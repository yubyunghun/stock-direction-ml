{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "144f3b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root → C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# NB20 — Build crypto artifacts (artifacts_crypto/)\n",
    "from pathlib import Path\n",
    "import sys, json, numpy as np, pandas as pd\n",
    "\n",
    "def find_repo_root(start: Path, must_have=(\"data\", \"artifacts\")) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if all((cur/m).exists() for m in must_have): return cur\n",
    "        cur = cur.parent\n",
    "    if start.name.lower()==\"notebooks\" and all((start.parent/m).exists() for m in must_have):\n",
    "        return start.parent.resolve()\n",
    "    raise FileNotFoundError(\"Repo root not found\")\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd())\n",
    "if str(ROOT) not in sys.path: sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"Repo root →\", ROOT)\n",
    "from app.lib_features import add_nb02_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f738051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ybh11\\AppData\\Local\\Temp\\ipykernel_12724\\3892478497.py:34: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df = df.merge(btc_ref, on=\"date\", how=\"left\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC-USD: rows=2489 | missing=None\n",
      "ETH-USD: rows=2489 | missing=['spy_close']\n",
      "Built crypto frame: {'BTC-USD': 2489, 'ETH-USD': 2489} | cols: 22\n",
      "Missing columns after concat: None\n",
      "        date         open         high          low        close      volume  \\\n",
      "0 2019-01-01  3746.713379  3850.913818  3707.231201  3843.520020  4324200990   \n",
      "1 2019-01-02  3849.216309  3947.981201  3817.409424  3943.409424  5244856836   \n",
      "2 2019-01-03  3931.048584  3935.685059  3826.222900  3836.741211  4530215219   \n",
      "\n",
      "    ticker    spy_close      ret1  ret5  ...  volz       rsi14      macd  \\\n",
      "0  BTC-USD  3843.520020       NaN   NaN  ...   NaN         NaN  0.000000   \n",
      "1  BTC-USD  3943.409424  0.025989   NaN  ...   NaN  100.000000  7.968386   \n",
      "2  BTC-USD  3836.741211 -0.027050   NaN  ...   NaN   92.409202  5.611470   \n",
      "\n",
      "   macd_signal  mkt_ret1  mkt_ret5  vix_close  vix_chg1  ret_next  y  \n",
      "0     0.000000       NaN       NaN        NaN       NaN  0.025989  1  \n",
      "1     1.593677  0.025989       NaN        NaN       NaN -0.027050  0  \n",
      "2     2.397236 -0.027050       NaN        NaN       NaN  0.005467  1  \n",
      "\n",
      "[3 rows x 22 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ybh11\\AppData\\Local\\Temp\\ipykernel_12724\\3892478497.py:34: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df = df.merge(btc_ref, on=\"date\", how=\"left\")\n"
     ]
    }
   ],
   "source": [
    "# NB20 — Fetch crypto data & build NB02C features (flatten columns per ticker)\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from app.lib_features import add_nb02_features  # from NB18\n",
    "\n",
    "tickers = [\"BTC-USD\", \"ETH-USD\"]  # add more later\n",
    "start   = \"2019-01-01\"\n",
    "end     = None  # to today\n",
    "\n",
    "REQ_COLS = [\n",
    "    \"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"ticker\",\n",
    "    \"ret1\",\"ret5\",\"ret10\",\"vol10\",\"volz\",\"rsi14\",\"macd\",\"macd_signal\",\n",
    "    \"spy_close\",\"mkt_ret1\",\"mkt_ret5\",\"vix_close\",\"vix_chg1\",\n",
    "    \"ret_next\",\"y\",\n",
    "]\n",
    "\n",
    "def fetch_base(ticker, start, end):\n",
    "    px = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False)\n",
    "    if px.empty:\n",
    "        raise ValueError(f\"No data for {ticker}\")\n",
    "    df = px.rename_axis(\"date\").reset_index()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.rename(columns={\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "    df = df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].copy()\n",
    "    df[\"ticker\"] = ticker\n",
    "    return df\n",
    "\n",
    "# Market proxy series (BTC close)\n",
    "btc_base = fetch_base(\"BTC-USD\", start, end)[[\"date\",\"close\"]].rename(columns={\"close\":\"btc_close\"})\n",
    "\n",
    "def enrich_crypto(df, btc_ref):\n",
    "    # merge BTC market proxy on date\n",
    "    df = df.merge(btc_ref, on=\"date\", how=\"left\")\n",
    "    # NB02 features on this ticker's close\n",
    "    df = add_nb02_features(df)\n",
    "    # Market proxies\n",
    "    df = df.rename(columns={\"btc_close\":\"spy_close\"})  # consistent name with equity pipeline\n",
    "    df[\"mkt_ret1\"] = df[\"spy_close\"].pct_change(1)\n",
    "    df[\"mkt_ret5\"] = df[\"spy_close\"].pct_change(5)\n",
    "    # VIX proxy from BTC realized vol\n",
    "    ret_btc = df[\"spy_close\"].pct_change()\n",
    "    vix_proxy = ret_btc.rolling(30).std() * np.sqrt(365) * 100.0\n",
    "    df[\"vix_close\"] = vix_proxy\n",
    "    df[\"vix_chg1\"]  = df[\"vix_close\"].pct_change(1)\n",
    "    # Targets\n",
    "    df[\"ret_next\"] = df[\"close\"].pct_change().shift(-1)\n",
    "    df[\"y\"] = (df[\"ret_next\"] > 0).astype(int)\n",
    "    return df\n",
    "\n",
    "def _flatten_to_single_level(dfc, ticker):\n",
    "    \"\"\"If columns are MultiIndex like ('open','BTC-USD'), keep only this ticker (or '') and flatten.\"\"\"\n",
    "    if not isinstance(dfc.columns, pd.MultiIndex):\n",
    "        return dfc\n",
    "    keep_cols = []\n",
    "    new_names = []\n",
    "    for col in dfc.columns:\n",
    "        if not isinstance(col, tuple):\n",
    "            keep_cols.append(col); new_names.append(col); continue\n",
    "        base, lvl2 = col\n",
    "        if lvl2 in (\"\", ticker):\n",
    "            keep_cols.append(col); new_names.append(base)\n",
    "    flat = dfc[keep_cols].copy()\n",
    "    flat.columns = new_names\n",
    "    return flat\n",
    "\n",
    "dfs = []\n",
    "for t in tickers:\n",
    "    base = fetch_base(t, start, end)\n",
    "    dfc  = enrich_crypto(base, btc_base)\n",
    "    dfc  = _flatten_to_single_level(dfc, t)  # <<< flatten here\n",
    "    missing = [c for c in REQ_COLS if c not in dfc.columns]\n",
    "    print(f\"{t}: rows={len(dfc)} | missing={missing if missing else 'None'}\")\n",
    "    dfs.append(dfc)\n",
    "\n",
    "# vertical concat of single-level frames\n",
    "df_all = pd.concat(dfs, ignore_index=True).sort_values([\"ticker\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "# final assert\n",
    "missing_all = [c for c in REQ_COLS if c not in df_all.columns]\n",
    "print(\"Built crypto frame:\", df_all[\"ticker\"].value_counts().to_dict(), \"| cols:\", len(df_all.columns))\n",
    "print(\"Missing columns after concat:\", missing_all if missing_all else \"None\")\n",
    "print(df_all.head(3))\n",
    "assert not missing_all, f\"Required columns missing: {missing_all}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacc555b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['ret1', 'ret5', 'ret10', 'vol10', 'volz', 'rsi14', 'macd', 'macd_signal', 'mkt_ret1', 'mkt_ret5', 'vix_chg1']\n",
      "Train: {'auc': 0.541502498415777, 'ap': 0.5619613535368221, 'brier': 0.24838391377896568, 'logloss': 0.6898855490406733}\n",
      "Test : {'auc': 0.5374152063312606, 'ap': 0.5619853446714549, 'brier': 0.24867839778011683, 'logloss': 0.6904981909660823}\n"
     ]
    }
   ],
   "source": [
    "# NB20 — Train StandardScaler + LogisticRegression for crypto\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss, f1_score\n",
    "import joblib\n",
    "\n",
    "# Feature set (crypto-friendly subset)\n",
    "CANDIDATES = [\n",
    "    \"ret1\",\"ret5\",\"ret10\",\"vol10\",\"volz\",\"rsi14\",\"macd\",\"macd_signal\",\n",
    "    \"mkt_ret1\",\"mkt_ret5\",\"vix_chg1\"\n",
    "]\n",
    "feat_list = [c for c in CANDIDATES if c in df_all.columns]\n",
    "print(\"Using features:\", feat_list)\n",
    "\n",
    "# Drop NA rows on features + labels\n",
    "tmp = df_all.dropna(subset=feat_list + [\"y\",\"ret_next\"]).copy()\n",
    "X = tmp[feat_list].to_numpy()\n",
    "y = tmp[\"y\"].astype(int).to_numpy()\n",
    "\n",
    "# Time-aware split: last 20% as test\n",
    "split_idx = int(len(tmp)*0.8)\n",
    "X_tr, X_te = X[:split_idx], X[split_idx:]\n",
    "y_tr, y_te = y[:split_idx], y[split_idx:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_trs = scaler.fit_transform(X_tr)\n",
    "X_tes = scaler.transform(X_te)\n",
    "\n",
    "lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"liblinear\")\n",
    "lr.fit(X_trs, y_tr)\n",
    "\n",
    "# Eval\n",
    "def pred_proba(model, X):\n",
    "    if hasattr(model,\"predict_proba\"):\n",
    "        p = model.predict_proba(X)\n",
    "        return p[:,1] if p.ndim==2 else p\n",
    "    if hasattr(model,\"decision_function\"):\n",
    "        s = model.decision_function(X); return 1/(1+np.exp(-s))\n",
    "    return np.clip(model.predict(X).astype(float), 0, 1)\n",
    "\n",
    "p_tr = np.clip(pred_proba(lr, X_trs), 1e-6, 1-1e-6)\n",
    "p_te = np.clip(pred_proba(lr, X_tes), 1e-6, 1-1e-6)\n",
    "\n",
    "def metrics(y, p):\n",
    "    def safe(fn,*a):\n",
    "        try: return float(fn(*a))\n",
    "        except: return float(\"nan\")\n",
    "    return dict(\n",
    "        auc=safe(roc_auc_score,y,p),\n",
    "        ap=safe(average_precision_score,y,p),\n",
    "        brier=safe(brier_score_loss,y,p),\n",
    "        logloss=safe(log_loss,y,p)\n",
    "    )\n",
    "\n",
    "print(\"Train:\", metrics(y_tr, p_tr))\n",
    "print(\"Test :\", metrics(y_te, p_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854ba859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen τ (by final equity): 0.4499999999999999\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts_crypto\\feature_list.json\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts_crypto\\scaler.joblib\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts_crypto\\lr.joblib\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts_crypto\\threshold.json\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts_crypto\\tau_map.json\n"
     ]
    }
   ],
   "source": [
    "# NB20 — pick τ by final equity; write artifacts_crypto/*\n",
    "ART_DIR = ROOT/\"artifacts_crypto\"\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simple equity objective to choose τ on test\n",
    "retn_te = tmp[\"ret_next\"].to_numpy()[split_idx:]\n",
    "def final_equity(retn, sig, fee_bps=5):\n",
    "    flips = np.zeros_like(sig)\n",
    "    if len(flips)>1: flips[1:] = (sig[1:] != sig[:-1]).astype(int)\n",
    "    fee = flips * (fee_bps/10000.0)\n",
    "    eq  = np.cumprod(1 + (retn*sig - fee))\n",
    "    return float(eq[-1]) if len(eq) else float(\"nan\")\n",
    "\n",
    "taus = np.linspace(0.05,0.95,91)\n",
    "eqs  = []\n",
    "for t in taus:\n",
    "    sig = (p_te >= t).astype(int)\n",
    "    eqs.append(final_equity(retn_te, sig, fee_bps=5))\n",
    "tau_best = float(taus[int(np.nanargmax(eqs))])\n",
    "print(\"Chosen τ (by final equity):\", tau_best)\n",
    "\n",
    "# Save artifacts\n",
    "(Path := ART_DIR/\"feature_list.json\").write_text(json.dumps(feat_list, indent=2), encoding=\"utf-8\")\n",
    "joblib.dump(scaler, ART_DIR/\"scaler.joblib\")\n",
    "joblib.dump(lr,     ART_DIR/\"lr.joblib\")\n",
    "(ART_DIR/\"threshold.json\").write_text(json.dumps({\"tau\": tau_best}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Per-ticker τ map (seed from same τ; you can customize later)\n",
    "tau_map = {tk: tau_best for tk in df_all[\"ticker\"].unique()}\n",
    "(ART_DIR/\"tau_map.json\").write_text(json.dumps(tau_map, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Wrote:\", (ART_DIR/\"feature_list.json\").resolve())\n",
    "print(\"Wrote:\", (ART_DIR/\"scaler.joblib\").resolve())\n",
    "print(\"Wrote:\", (ART_DIR/\"lr.joblib\").resolve())\n",
    "print(\"Wrote:\", (ART_DIR/\"threshold.json\").resolve())\n",
    "print(\"Wrote:\", (ART_DIR/\"tau_map.json\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed8edb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts_crypto\\feature_list.json: True\n",
      "artifacts_crypto\\scaler.joblib: True\n",
      "artifacts_crypto\\lr.joblib: True\n",
      "artifacts_crypto\\threshold.json: True\n",
      "artifacts_crypto\\tau_map.json: True\n",
      "Loaded crypto artifacts — features: 11 | default τ: 0.4499999999999999\n",
      "BTC rows: 2379 | metrics (AUC, AP): 0.5372644590937243 0.5536785240780647\n"
     ]
    }
   ],
   "source": [
    "# NB20 — presence check\n",
    "targets = [\n",
    "    ART_DIR/\"feature_list.json\",\n",
    "    ART_DIR/\"scaler.joblib\",\n",
    "    ART_DIR/\"lr.joblib\",\n",
    "    ART_DIR/\"threshold.json\",\n",
    "    ART_DIR/\"tau_map.json\",\n",
    "]\n",
    "for t in targets:\n",
    "    print(f\"{t.relative_to(ROOT)}:\", t.exists())\n",
    "\n",
    "# Quick smoke: load via app loader (crypto)\n",
    "from app.lib_artifacts import load_artifacts\n",
    "from app.lib_features  import make_dataset\n",
    "\n",
    "feat_list2, scaler2, model2, tau_art2, tau_map2 = load_artifacts(\"crypto\")\n",
    "print(\"Loaded crypto artifacts — features:\", len(feat_list2), \"| default τ:\", tau_art2)\n",
    "\n",
    "# Build dataset for BTC only to test end-to-end\n",
    "btc_df = df_all.loc[df_all[\"ticker\"]==\"BTC-USD\"].copy()\n",
    "Xb, yb, rb, idxb, used = make_dataset(btc_df, feat_list2)\n",
    "pb = np.clip(pred_proba := (model2.predict_proba(scaler2.transform(Xb))[:,1]), 1e-6, 1-1e-6)\n",
    "print(\"BTC rows:\", len(pb), \"| metrics (AUC, AP):\",\n",
    "      float(roc_auc_score(yb, pb)) if yb is not None else \"n/a\",\n",
    "      float(average_precision_score(yb, pb)) if yb is not None else \"n/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478613b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the app (now with real crypto artifacts):\n",
      "  streamlit run app/streamlit_app.py\n",
      "In the sidebar:\n",
      "  • Data source = Fetch (Yahoo)\n",
      "  • Asset class = crypto\n",
      "  • Ticker = BTC-USD / ETH-USD\n",
      "\n",
      "Note: If you previously patched a fallback in streamlit_app.py, it's harmless to keep —\n",
      "      now that artifacts_crypto/ exists, the fallback path won't trigger.\n"
     ]
    }
   ],
   "source": [
    "print(\"Run the app (now with real crypto artifacts):\")\n",
    "print(\"  streamlit run app/streamlit_app.py\")\n",
    "print(\"In the sidebar:\")\n",
    "print(\"  • Data source = Fetch (Yahoo)\")\n",
    "print(\"  • Asset class = crypto\")\n",
    "print(\"  • Ticker = BTC-USD / ETH-USD\")\n",
    "print(\"\")\n",
    "print(\"Note: If you previously patched a fallback in streamlit_app.py, it's harmless to keep —\")\n",
    "print(\"      now that artifacts_crypto/ exists, the fallback path won't trigger.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
