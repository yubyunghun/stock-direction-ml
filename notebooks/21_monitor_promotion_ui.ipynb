{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41acbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root → C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# NB21 — repo root\n",
    "from pathlib import Path\n",
    "def find_repo_root(start: Path, must_have=(\"data\",\"artifacts\")) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if all((cur/m).exists() for m in must_have): return cur\n",
    "        cur = cur.parent\n",
    "    if start.name.lower()==\"notebooks\" and all((start.parent/m).exists() for m in must_have):\n",
    "        return start.parent.resolve()\n",
    "    raise FileNotFoundError(\"Repo root not found\")\n",
    "ROOT = find_repo_root(Path.cwd())\n",
    "print(\"Repo root →\", ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5844c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\app\\lib_monitor.py\n"
     ]
    }
   ],
   "source": [
    "# NB21 — write app/lib_monitor.py\n",
    "from textwrap import dedent\n",
    "code = dedent(\"\"\"\n",
    "# app/lib_monitor.py\n",
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def _load_json(p: Path) -> Dict[str, Any]:\n",
    "    if not p.exists(): return {}\n",
    "    try:\n",
    "        return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def load_monitoring(root: Path) -> Tuple[dict, dict, dict]:\n",
    "    art = root / \"artifacts\"\n",
    "    monitor   = _load_json(art / \"monitor_snapshot.json\")\n",
    "    paper     = _load_json(art / \"paper_trade.json\")\n",
    "    backtest  = _load_json(art / \"backtest_summary.json\")\n",
    "    return monitor, paper, backtest\n",
    "\n",
    "def _get(d: dict, *keys, default=None):\n",
    "    cur = d\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur: return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "def summarize_monitor(m: dict) -> dict:\n",
    "    # Flexible: pull whatever exists\n",
    "    return {\n",
    "        \"updated_at\":        _get(m, \"updated_at\") or _get(m, \"timestamp\"),\n",
    "        \"window_days\":       _get(m, \"window_days\") or _get(m, \"config\", \"window_days\"),\n",
    "        \"trades_60d\":        _get(m, \"kpis\", \"num_trades_60d\") or _get(m, \"num_trades_60d\"),\n",
    "        \"winrate_60d\":       _get(m, \"kpis\", \"winrate_60d\") or _get(m, \"winrate_60d\"),\n",
    "        \"avg_prob_60d\":      _get(m, \"kpis\", \"avg_prob_60d\") or _get(m, \"avg_prob_60d\"),\n",
    "        \"avg_ret_60d\":       _get(m, \"kpis\", \"avg_ret_60d\") or _get(m, \"avg_ret_60d\"),\n",
    "        \"psi_max\":           _max_numeric(_get(m, \"drift\", \"psi_by_feature\")),\n",
    "        \"ks_max\":            _max_numeric(_get(m, \"drift\", \"ks_by_feature\")),\n",
    "    }\n",
    "\n",
    "def summarize_paper(p: dict) -> dict:\n",
    "    return {\n",
    "        \"start\":      _get(p, \"start\") or _get(p, \"period\", \"start\"),\n",
    "        \"end\":        _get(p, \"end\")   or _get(p, \"period\", \"end\"),\n",
    "        \"final_equity\": _get(p, \"final_equity\") or _get(p, \"equity\", \"final\"),\n",
    "        \"num_trades\": _get(p, \"num_trades\") or (len(_get(p, \"trades\", default=[])) if isinstance(_get(p,\"trades\"), list) else None),\n",
    "    }\n",
    "\n",
    "def summarize_backtest(b: dict) -> dict:\n",
    "    return {\n",
    "        \"fee_bps\":        _get(b, \"fee_bps\"),\n",
    "        \"auc\":            _get(b, \"metrics\", \"auc\") or _get(b, \"auc\"),\n",
    "        \"threshold_tau\":  _get(b, \"threshold\", \"tau\") or _get(b, \"tau\"),\n",
    "        \"parity_ok\":      bool(_get(b, \"parity_ok\") or _get(b, \"parity\", \"ok\") or _get(b, \"matched\")),\n",
    "    }\n",
    "\n",
    "def _max_numeric(d: dict | None):\n",
    "    if not isinstance(d, dict): return None\n",
    "    try:\n",
    "        vals = [float(v) for v in d.values() if v is not None]\n",
    "        return max(vals) if vals else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def promotion_checks(mon: dict, back: dict) -> dict:\n",
    "    # Heuristic rules; only enforce if metric is present.\n",
    "    rules = []\n",
    "    status = \"PASS\"\n",
    "    # R1: winrate >= 0.52 (if we have it)\n",
    "    wr = mon.get(\"winrate_60d\")\n",
    "    if wr is not None:\n",
    "        ok = wr >= 0.52\n",
    "        rules.append({\"rule\":\"winrate_60d >= 0.52\", \"value\":wr, \"pass\":ok})\n",
    "        if not ok: status = \"HOLD\"\n",
    "    # R2: psi_max <= 0.2 (drift)\n",
    "    psi = mon.get(\"psi_max\")\n",
    "    if psi is not None:\n",
    "        ok = psi <= 0.2\n",
    "        rules.append({\"rule\":\"psi_max <= 0.2\", \"value\":psi, \"pass\":ok})\n",
    "        if not ok: status = \"HOLD\"\n",
    "    # R3: backtest parity ok (if available)\n",
    "    parity = back.get(\"parity_ok\")\n",
    "    if parity is not None:\n",
    "        ok = bool(parity)\n",
    "        rules.append({\"rule\":\"backtest parity ok\", \"value\":parity, \"pass\":ok})\n",
    "        if not ok: status = \"HOLD\"\n",
    "    # If no rules were evaluated, mark as UNKNOWN\n",
    "    if not rules: status = \"UNKNOWN\"\n",
    "    return {\"status\": status, \"rules\": rules}\n",
    "\"\"\").lstrip()\n",
    "out = (ROOT/\"app\"/\"lib_monitor.py\")\n",
    "out.write_text(code, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", out.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b1be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\app\\streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "# NB21 — overwrite app/streamlit_app.py with Monitoring tab\n",
    "from textwrap import dedent\n",
    "code = dedent(\"\"\"\n",
    "# app/streamlit_app.py — model & monitoring tabs\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, streamlit as st\n",
    "\n",
    "from app.config import ROOT, DEFAULT_TAU\n",
    "from app.lib_artifacts import load_artifacts\n",
    "from app.lib_fetch import load_repo_df, fetch_equity_df, fetch_crypto_df\n",
    "from app.lib_features import make_dataset\n",
    "from app.lib_eval import predict_proba, metrics_all, tau_sweep\n",
    "from app.lib_monitor import load_monitoring, summarize_monitor, summarize_paper, summarize_backtest, promotion_checks\n",
    "\n",
    "st.set_page_config(page_title=\"Direction Classifier\", layout=\"wide\")\n",
    "st.title(\"📈 Direction Classifier — Any Ticker (Equities & Crypto)\")\n",
    "\n",
    "# ---- Sidebar: data source ----\n",
    "with st.sidebar:\n",
    "    st.header(\"Data source\")\n",
    "    src = st.radio(\"Choose\", [\"Repo file\",\"Fetch (Yahoo)\"], index=0)\n",
    "    asset_class = st.selectbox(\"Asset class\", [\"equity\",\"crypto\"], index=0)\n",
    "\n",
    "    if src == \"Repo file\":\n",
    "        df = load_repo_df()\n",
    "        if \"ticker\" in df.columns:\n",
    "            ticks = sorted(df[\"ticker\"].dropna().unique().tolist())\n",
    "            default = df[\"ticker\"].value_counts().idxmax()\n",
    "            ticker = st.selectbox(\"Ticker\", ticks, index=max(0, ticks.index(default)))\n",
    "            df = df.loc[df[\"ticker\"]==ticker].copy()\n",
    "            st.caption(f\"Ticker: **{ticker}**  •  Rows: {len(df)}\")\n",
    "        else:\n",
    "            ticker = None\n",
    "            st.caption(\"No 'ticker' column; using all rows.\")\n",
    "        if \"date\" in df.columns:\n",
    "            dmin, dmax = df[\"date\"].min(), df[\"date\"].max()\n",
    "            start, end = st.date_input(\"Date range\", value=(dmin.date(), dmax.date()),\n",
    "                                       min_value=dmin.date(), max_value=dmax.date())\n",
    "            df = df.loc[df[\"date\"].dt.date.between(start, end)].copy()\n",
    "    else:\n",
    "        ticker = st.text_input(\"Ticker\", value=(\"AAPL\" if asset_class==\"equity\" else \"BTC-USD\"))\n",
    "        dates = st.date_input(\"Fetch range (UTC)\", value=(pd.to_datetime(\"2023-01-01\").date(), pd.Timestamp.today().date()))\n",
    "        btn = st.button(\"Fetch data\")\n",
    "        if not btn:\n",
    "            st.stop()\n",
    "        try:\n",
    "            if asset_class==\"equity\":\n",
    "                df = fetch_equity_df(ticker, dates[0], dates[1])\n",
    "            else:\n",
    "                df = fetch_crypto_df(ticker, dates[0], dates[1])\n",
    "            st.success(f\"Fetched {len(df)} rows for {ticker}\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Fetch failed: {e}\"); st.stop()\n",
    "\n",
    "# ---- Artifacts (with crypto folder support for tau_map) ----\n",
    "try:\n",
    "    feature_list, scaler, model, tau_art, tau_map = load_artifacts(asset_class=(\"equity\" if asset_class==\"equity\" else \"crypto\"))\n",
    "except Exception:\n",
    "    st.warning(\"Artifacts not found for selected asset class; falling back to equity artifacts.\")\n",
    "    feature_list, scaler, model, tau_art, tau_map = load_artifacts(\"equity\")\n",
    "default_tau = float(tau_map.get(ticker, tau_art if tau_art is not None else DEFAULT_TAU)) if ticker else (tau_art or DEFAULT_TAU)\n",
    "\n",
    "# ---- Dataset & predictions ----\n",
    "X, y, retn, idx, used_cols = make_dataset(df, feature_list)\n",
    "if len(X)==0: st.error(\"No usable rows after feature alignment/NA drop.\"); st.stop()\n",
    "Xs = scaler.transform(X)\n",
    "p  = np.clip(predict_proba(model, Xs), 1e-6, 1-1e-6)\n",
    "\n",
    "# ---- Tabs ----\n",
    "tab_model, tab_monitor = st.tabs([\"🔮 Model\", \"🛡️ Monitoring & Promotion\"])\n",
    "\n",
    "with tab_model:\n",
    "    with st.sidebar:\n",
    "        tau     = st.slider(\"Decision threshold (τ)\", 0.00, 1.00, value=float(round(default_tau,2)), step=0.01)\n",
    "        fee_bps = st.number_input(\"Fee (bps) per position flip\", value=5, min_value=0, max_value=100, step=1)\n",
    "\n",
    "    # Metrics\n",
    "    c1,c2,c3,c4 = st.columns(4)\n",
    "    if y is not None and len(y)==len(p):\n",
    "        m = metrics_all(y, p)\n",
    "        c1.metric(\"ROC AUC\", f\"{m['auc']:.3f}\" if np.isfinite(m['auc']) else \"n/a\")\n",
    "        c2.metric(\"PR AUC\",  f\"{m['ap']:.3f}\" if np.isfinite(m['ap']) else \"n/a\")\n",
    "        c3.metric(\"Brier\",    f\"{m['brier']:.4f}\" if np.isfinite(m['brier']) else \"n/a\")\n",
    "        c4.metric(\"Log Loss\", f\"{m['logloss']:.4f}\" if np.isfinite(m['logloss']) else \"n/a\")\n",
    "    else:\n",
    "        for c in (c1,c2,c3,c4): c.metric(\"—\",\"—\")\n",
    "        st.info(\"Labels not available; showing predictions/equity only.\")\n",
    "\n",
    "    # Equity vs B&H\n",
    "    sig = (p >= tau).astype(int)\n",
    "    flips = np.zeros_like(sig)\n",
    "    if len(flips)>1: flips[1:] = (sig[1:] != sig[:-1]).astype(int)\n",
    "    fee = flips * (fee_bps/10000.0)\n",
    "    eq  = np.cumprod(1 + (retn*sig - fee))\n",
    "    bh  = np.cumprod(1 + retn)\n",
    "\n",
    "    dates_axis = (df.iloc[idx][\"date\"].values if \"date\" in df.columns else df.index.values)\n",
    "    st.subheader(\"Equity Curve vs. Buy & Hold\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dates_axis, bh,  label=\"Buy & Hold\")\n",
    "    ax.plot(dates_axis, eq,  label=f\"Strategy (τ={tau:.2f}, fee={fee_bps}bps)\")\n",
    "    ax.set_xlabel(\"Date\" if \"date\" in df.columns else \"Index\"); ax.set_ylabel(\"Equity (×)\")\n",
    "    ax.legend(); st.pyplot(fig)\n",
    "\n",
    "    # τ-sweep\n",
    "    with st.expander(\"τ-sweep (F1 & Final Equity)\"):\n",
    "        if y is not None and len(y)==len(p):\n",
    "            grid, f1s, finals = tau_sweep(y, p, retn, fee_bps=fee_bps)\n",
    "            best_f1_tau = float(grid[int(np.nanargmax(f1s))])\n",
    "            best_eq_tau = float(grid[int(np.nanargmax(finals))])\n",
    "            st.write({\"best_f1_tau\":best_f1_tau, \"best_final_equity_tau\":best_eq_tau})\n",
    "            f, axf = plt.subplots(); axf.plot(grid, f1s, label=\"F1 vs τ\"); axf.set_xlabel(\"τ\"); axf.set_ylabel(\"F1\"); axf.legend(); st.pyplot(f)\n",
    "        else:\n",
    "            st.info(\"Labels not available; τ-sweep (F1) disabled.\")\n",
    "\n",
    "    # Tail & CSV\n",
    "    pred_df = pd.DataFrame({\"date\": dates_axis, \"proba\": p, \"signal\": sig})\n",
    "    if \"close\" in df.columns: pred_df[\"close\"] = df.iloc[idx][\"close\"].values\n",
    "    st.subheader(\"Latest predictions (tail)\")\n",
    "    st.dataframe(pred_df.tail(min(12, len(pred_df))))\n",
    "    st.download_button(\"Download predictions CSV\",\n",
    "        data=pred_df.to_csv(index=False).encode(\"utf-8\"),\n",
    "        file_name=\"predictions.csv\", mime=\"text/csv\")\n",
    "\n",
    "with tab_monitor:\n",
    "    st.subheader(\"Monitoring snapshot & Promotion readiness\")\n",
    "    mon_raw, paper_raw, back_raw = load_monitoring(ROOT)\n",
    "    mon = summarize_monitor(mon_raw) if mon_raw else {}\n",
    "    pap = summarize_paper(paper_raw) if paper_raw else {}\n",
    "    bak = summarize_backtest(back_raw) if back_raw else {}\n",
    "\n",
    "    c1,c2,c3,c4 = st.columns(4)\n",
    "    c1.metric(\"Winrate (60d)\", f\"{mon.get('winrate_60d'):.2%}\" if isinstance(mon.get('winrate_60d'), (int,float)) else \"n/a\")\n",
    "    c2.metric(\"Trades (60d)\",  f\"{mon.get('trades_60d')}\" if mon.get('trades_60d') is not None else \"n/a\")\n",
    "    c3.metric(\"PSI max\",       f\"{mon.get('psi_max'):.3f}\" if isinstance(mon.get('psi_max'), (int,float)) else \"n/a\")\n",
    "    c4.metric(\"KS max\",        f\"{mon.get('ks_max'):.3f}\" if isinstance(mon.get('ks_max'), (int,float)) else \"n/a\")\n",
    "\n",
    "    c5,c6,c7 = st.columns(3)\n",
    "    c5.metric(\"Paper final equity\", f\"{pap.get('final_equity'):.3f}\" if isinstance(pap.get('final_equity'), (int,float)) else \"n/a\")\n",
    "    c6.metric(\"Backtest AUC\",       f\"{bak.get('auc'):.3f}\" if isinstance(bak.get('auc'), (int,float)) else \"n/a\")\n",
    "    c7.metric(\"Backtest parity\",    \"OK\" if bak.get('parity_ok') else (\"n/a\" if bak.get('parity_ok') is None else \"FAIL\"))\n",
    "\n",
    "    checks = promotion_checks(mon, bak)\n",
    "    st.markdown(f\"**Promotion status:** {'🟢 PASS' if checks['status']=='PASS' else ('🟡 UNKNOWN' if checks['status']=='UNKNOWN' else '🟠 HOLD')}\")\n",
    "    if checks[\"rules\"]:\n",
    "        st.write(pd.DataFrame(checks[\"rules\"]))\n",
    "\n",
    "    with st.expander(\"Raw artifacts\"):\n",
    "        colA, colB, colC = st.columns(3)\n",
    "        colA.download_button(\"monitor_snapshot.json\", data=(str(mon_raw).encode('utf-8') if mon_raw else b''), file_name=\"monitor_snapshot.json\")\n",
    "        colB.download_button(\"paper_trade.json\", data=(str(paper_raw).encode('utf-8') if paper_raw else b''), file_name=\"paper_trade.json\")\n",
    "        colC.download_button(\"backtest_summary.json\", data=(str(back_raw).encode('utf-8') if back_raw else b''), file_name=\"backtest_summary.json\")\n",
    "\n",
    "    if not mon_raw:  st.info(\"No artifacts/monitor_snapshot.json found — NB11 creates it.\")\n",
    "    if not paper_raw: st.info(\"No artifacts/paper_trade.json found — NB10/NB14 create it.\")\n",
    "    if not back_raw:  st.info(\"No artifacts/backtest_summary.json found — NB7 writes it.\")\n",
    "\n",
    "st.caption(\"Monitoring shows 60d KPIs, drift, backtest parity, and a promotion recommendation.\")\n",
    "\"\"\").lstrip()\n",
    "out = (ROOT/\"app\"/\"streamlit_app.py\")\n",
    "out.write_text(code, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", out.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da9c2b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax OK\n"
     ]
    }
   ],
   "source": [
    "# NB21 — syntax check\n",
    "for t in [\"app/lib_monitor.py\", \"app/streamlit_app.py\"]:\n",
    "    src = (ROOT/t).read_text(encoding=\"utf-8\")\n",
    "    compile(src, str(ROOT/t), \"exec\")\n",
    "print(\"Syntax OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa1be8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/monitor_snapshot.json    : True\n",
      "artifacts/paper_trade.json         : True\n",
      "artifacts/backtest_summary.json    : True\n"
     ]
    }
   ],
   "source": [
    "# NB21 — presence check for monitoring artifacts\n",
    "arts = [\"artifacts/monitor_snapshot.json\", \"artifacts/paper_trade.json\", \"artifacts/backtest_summary.json\"]\n",
    "for a in arts:\n",
    "    print(f\"{a:35s}:\", (ROOT/a).exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b6552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run the app with the new Monitoring tab:\n",
      "  streamlit run app/streamlit_app.py\n",
      "Then open the '🛡️ Monitoring & Promotion' tab.\n"
     ]
    }
   ],
   "source": [
    "print(\"Run the app with the new Monitoring tab:\")\n",
    "print(\"  streamlit run app/streamlit_app.py\")\n",
    "print(\"Then open the '🛡️ Monitoring & Promotion' tab.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
