{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee072b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root → C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\n",
      "reports ok\n",
      "reports\\figures ok\n",
      "reports\\demo ok\n"
     ]
    }
   ],
   "source": [
    "# NB22 — repo root + folders\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path, must_have=(\"data\",\"artifacts\")) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if all((cur/m).exists() for m in must_have): return cur\n",
    "        cur = cur.parent\n",
    "    if start.name.lower()==\"notebooks\" and all((start.parent/m).exists() for m in must_have):\n",
    "        return start.parent.resolve()\n",
    "    raise FileNotFoundError(\"Repo root not found\")\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd())\n",
    "print(\"Repo root →\", ROOT)\n",
    "\n",
    "# Folders we’ll use\n",
    "(REPORTS := ROOT/\"reports\").mkdir(parents=True, exist_ok=True)\n",
    "(FIGS    := REPORTS/\"figures\").mkdir(parents=True, exist_ok=True)\n",
    "(DEMO    := REPORTS/\"demo\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for p in [REPORTS, FIGS, DEMO]:\n",
    "    print(p.relative_to(ROOT), \"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fc4ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\README.md\n"
     ]
    }
   ],
   "source": [
    "# NB22 — write README.md (safe: no triple-quote pitfalls)\n",
    "from pathlib import Path\n",
    "\n",
    "lines = [\n",
    "\"# Stock/Crypto Direction Classifier\",\n",
    "\"\",\n",
    "\"An end-to-end ML project that predicts the **next-day direction** (up/down) for equities and crypto, with:\",\n",
    "\"- Data prep & features (NB01–NB04)\",\n",
    "\"- Model training + eval (Logistic Regression) (NB05–NB06, NB13)\",\n",
    "\"- Backtest + threshold parity (NB07)\",\n",
    "\"- Monitoring + promotion checks (NB10–NB12, NB21)\",\n",
    "\"- Daily runner (NB14)\",\n",
    "\"- Streamlit demo app (NB15–NB16, NB18–NB21)\",\n",
    "\"- Crypto artifacts (NB20)\",\n",
    "\"\",\n",
    "\"> **Not financial advice.** This is a demo research system.\",\n",
    "\"\",\n",
    "\"## Quickstart\",\n",
    "\"\",\n",
    "\"### Run locally\",\n",
    "\"```bash\",\n",
    "\"# from the repo folder that contains app/\",\n",
    "\"python -m pip install -r notebooks/requirements.txt\",\n",
    "\"python -m streamlit run app/streamlit_app.py\",\n",
    "\"```\",\n",
    "\"\",\n",
    "\"### Streamlit Cloud\",\n",
    "\"- Main file path: `app/streamlit_app.py`\",\n",
    "\"- Secrets are not required (uses Yahoo Finance for public data).\",\n",
    "\"\",\n",
    "\"## App Features\",\n",
    "\"- **Data source:** Repo file or live fetch (Yahoo) for equities & crypto.\",\n",
    "\"- **Metrics:** ROC AUC, PR AUC, Brier, LogLoss (when labels exist).\",\n",
    "\"- **Charts:** Equity vs Buy & Hold, ROC/PR, Calibration, τ-sweep.\",\n",
    "\"- **Controls:** Decision threshold (τ) & fee (bps). Per-ticker τ defaults.\",\n",
    "\"- **Monitoring tab:** 60-day KPIs, drift summary (PSI/KS), backtest parity, promotion recommendation.\",\n",
    "\"\",\n",
    "\"### Screenshots (placeholders)\",\n",
    "\"Add screenshots here (save under `reports/figures/`):\",\n",
    "\"- `reports/figures/screenshot_model.png` – Model tab\",\n",
    "\"- `reports/figures/screenshot_monitor.png` – Monitoring tab\",\n",
    "\"\",\n",
    "\"## Repo Layout\",\n",
    "\"```\",\n",
    "\"app/\",\n",
    "\"  config.py\",\n",
    "\"  lib_artifacts.py\",\n",
    "\"  lib_features.py\",\n",
    "\"  lib_fetch.py\",\n",
    "\"  lib_eval.py\",\n",
    "\"  lib_monitor.py\",\n",
    "\"  streamlit_app.py\",\n",
    "\"artifacts/                 # equity artifacts (features, scaler, lr, threshold, tau_map)\",\n",
    "\"artifacts_crypto/          # crypto artifacts (NB20)\",\n",
    "\"data/                      # df_nb02.* and signals.csv\",\n",
    "\"reports/\",\n",
    "\"  figures/\",\n",
    "\"  demo/                    # small prediction CSVs for sharing\",\n",
    "\"notebooks/                 # NB01–NB22\",\n",
    "\"```\",\n",
    "\"\",\n",
    "\"## How It Works (short)\",\n",
    "\"1. **Features:** Returns (1/5/10), realized vol (10d), z-vol, RSI(14), MACD+signal, market ret (SPY/BTC), VIX or BTC-vol proxy.\",\n",
    "\"2. **Model:** Logistic Regression on standardized features.\",\n",
    "\"3. **Threshold (τ):** Picked by final equity in backtest; can be per-ticker (`artifacts/*/tau_map.json`).\",\n",
    "\"4. **Equity curve:** Long-only (1 = long, 0 = cash). Fee applied per position flip.\",\n",
    "\"5. **Monitoring:** 60-day KPIs + drift + backtest parity → promotion PASS/HOLD.\",\n",
    "\"\",\n",
    "\"## Repro & Daily\",\n",
    "\"- **Daily runner:** NB14 (updates data/paper trade).\",\n",
    "\"- **Monitoring snapshot:** NB11 outputs `artifacts/monitor_snapshot.json`.\",\n",
    "\"- **Backtest summary:** NB07 writes `artifacts/backtest_summary.json`.\",\n",
    "\"\",\n",
    "\"## Limitations\",\n",
    "\"- AUC is modest (≈0.5–0.55 on splits); demonstration focus.\",\n",
    "\"- Long-only, 1-day horizon; no risk sizing.\",\n",
    "\"- Yahoo data used for convenience.\",\n",
    "\"\",\n",
    "\"## License\",\n",
    "\"MIT (or your choice)\",\n",
    "]\n",
    "\n",
    "out = (ROOT / \"README.md\")\n",
    "out.write_text(\"\\n\".join(lines) + \"\\n\", encoding=\"utf-8\")\n",
    "print(\"Wrote:\", out.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1aaf8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\reports\\demo\\preds_equity_AAPL.csv\n",
      "           date ticker       close     proba  signal  tau_used\n",
      "2683 2025-10-08   AAPL  258.059998  0.528984       1      0.45\n",
      "2684 2025-10-09   AAPL  254.039993  0.561558       1      0.45\n",
      "2685 2025-10-10   AAPL  245.270004  0.565084       1      0.45\n"
     ]
    }
   ],
   "source": [
    "# NB22 — export demo predictions (equity)\n",
    "import numpy as np, pandas as pd\n",
    "from app.lib_artifacts import load_artifacts\n",
    "from app.lib_features  import make_dataset\n",
    "\n",
    "# Load repo df\n",
    "if (ROOT/\"data/df_nb02.csv\").exists():\n",
    "    df = pd.read_csv(ROOT/\"data/df_nb02.csv\")\n",
    "elif (ROOT/\"data/df_nb02.parquet\").exists():\n",
    "    df = pd.read_parquet(ROOT/\"data/df_nb02.parquet\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing data/df_nb02.* in data/\")\n",
    "\n",
    "# Parse date\n",
    "for c in [\"date\",\"Date\",\"timestamp\",\"ts\"]:\n",
    "    if c in df.columns:\n",
    "        try: df[c] = pd.to_datetime(df[c])\n",
    "        except: pass\n",
    "        if c != \"date\": df[\"date\"] = df[c]\n",
    "        break\n",
    "\n",
    "# Pick a ticker (prefer AAPL)\n",
    "ticker = None\n",
    "if \"ticker\" in df.columns and \"AAPL\" in set(df[\"ticker\"]):\n",
    "    ticker = \"AAPL\"\n",
    "elif \"ticker\" in df.columns:\n",
    "    ticker = df[\"ticker\"].value_counts().idxmax()\n",
    "if ticker:\n",
    "    df = df.loc[df[\"ticker\"]==ticker].copy()\n",
    "\n",
    "feature_list, scaler, model, tau_art, tau_map = load_artifacts(\"equity\")\n",
    "default_tau = float(tau_map.get(ticker, tau_art if tau_art is not None else 0.59)) if ticker else (tau_art or 0.59)\n",
    "\n",
    "X, y, retn, idx, used_cols = make_dataset(df, feature_list)\n",
    "Xs = scaler.transform(X)\n",
    "if hasattr(model, \"predict_proba\"):\n",
    "    p = model.predict_proba(Xs); p = p[:,1] if p.ndim==2 else p\n",
    "elif hasattr(model, \"decision_function\"):\n",
    "    s = model.decision_function(Xs); p = 1/(1+np.exp(-s))\n",
    "else:\n",
    "    p = np.clip(model.predict(Xs).astype(float), 0, 1)\n",
    "p = np.clip(p, 1e-6, 1-1e-6)\n",
    "sig = (p >= default_tau).astype(int)\n",
    "\n",
    "pred = pd.DataFrame({\n",
    "    \"date\": (df.iloc[idx][\"date\"].values if \"date\" in df.columns else df.index.values),\n",
    "    \"ticker\": ticker if ticker else (df[\"ticker\"].iloc[0] if \"ticker\" in df.columns else \"UNKNOWN\"),\n",
    "    \"close\": (df.iloc[idx][\"close\"].values if \"close\" in df.columns else np.nan),\n",
    "    \"proba\": p,\n",
    "    \"signal\": sig,\n",
    "    \"tau_used\": default_tau\n",
    "})\n",
    "out_csv = (ROOT/\"reports\"/\"demo\"/f\"preds_equity_{pred['ticker'].iloc[0]}.csv\")\n",
    "pred.to_csv(out_csv, index=False)\n",
    "print(\"Wrote:\", out_csv.resolve())\n",
    "print(pred.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d3f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: {'date': (255,), 'ticker': (255,), 'close': (255,), 'proba': (255,), 'signal': (255,), 'tau_used': (255,)}\n",
      "Wrote: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\reports\\demo\\preds_crypto_BTCUSD.csv\n",
      "          date   ticker          close     proba  signal  tau_used\n",
      "252 2025-10-23  BTC-USD  110069.726562  0.499439       1      0.45\n",
      "253 2025-10-24  BTC-USD  111033.921875  0.509068       1      0.45\n",
      "254 2025-10-25  BTC-USD  111641.726562  0.510362       1      0.45\n"
     ]
    }
   ],
   "source": [
    "# NB22 — export demo predictions (crypto) — bullet-proof\n",
    "import numpy as np, pandas as pd\n",
    "from app.lib_fetch     import fetch_crypto_df\n",
    "from app.lib_artifacts import load_artifacts\n",
    "from app.lib_features  import make_dataset\n",
    "\n",
    "ticker = \"BTC-USD\"\n",
    "start = (pd.Timestamp.today() - pd.Timedelta(days=365)).date()\n",
    "end   = pd.Timestamp.today().date()\n",
    "\n",
    "# Build df with NB02C features\n",
    "dfc = fetch_crypto_df(ticker, start, end)  # may show a PerformanceWarning; OK\n",
    "\n",
    "# Load crypto artifacts\n",
    "feature_list, scaler, model, tau_art, tau_map = load_artifacts(\"crypto\")\n",
    "default_tau = float(tau_map.get(ticker, tau_art if tau_art is not None else 0.59))\n",
    "\n",
    "# Dataset aligned to features\n",
    "X, y, retn, idx, used_cols = make_dataset(dfc, feature_list)\n",
    "Xs = scaler.transform(X)\n",
    "\n",
    "# Probabilities (1D)\n",
    "if hasattr(model, \"predict_proba\"):\n",
    "    p = model.predict_proba(Xs); p = p[:,1] if p.ndim==2 else p\n",
    "elif hasattr(model, \"decision_function\"):\n",
    "    s = model.decision_function(Xs); p = 1/(1+np.exp(-s))\n",
    "else:\n",
    "    p = np.clip(model.predict(Xs).astype(float), 0, 1)\n",
    "p   = np.clip(np.asarray(p).ravel(), 1e-6, 1-1e-6)\n",
    "sig = (p >= default_tau).astype(int).ravel()\n",
    "\n",
    "# Slice to used rows\n",
    "df_used = dfc.iloc[idx].reset_index(drop=True)\n",
    "n = len(df_used)\n",
    "assert len(p) == n and len(sig) == n, f\"Length mismatch: p={len(p)} sig={len(sig)} rows={n}\"\n",
    "\n",
    "# --- helpers to extract date/close robustly ---\n",
    "def extract_dates(df_):\n",
    "    if \"date\" in df_.columns:\n",
    "        return pd.to_datetime(df_[\"date\"], errors=\"coerce\").to_numpy()\n",
    "    return np.asarray(df_.index.values)\n",
    "\n",
    "def extract_close(df_, tk: str):\n",
    "    # returns 1D float array; falls back to NaN if anything odd\n",
    "    try:\n",
    "        # If MultiIndex columns, try ('close', tk) or ('close','')\n",
    "        if isinstance(df_.columns, pd.MultiIndex):\n",
    "            if (\"close\", tk) in df_.columns:\n",
    "                s = df_[(\"close\", tk)]\n",
    "            elif (\"close\",\"\") in df_.columns:\n",
    "                s = df_[(\"close\",\"\")]\n",
    "            else:\n",
    "                # flatten and try again\n",
    "                flat_names = []\n",
    "                for c in df_.columns:\n",
    "                    if isinstance(c, tuple):\n",
    "                        flat_names.append(\"_\".join(str(x) for x in c if str(x)))\n",
    "                    else:\n",
    "                        flat_names.append(str(c))\n",
    "                df2 = df_.copy()\n",
    "                df2.columns = flat_names\n",
    "                if f\"close_{tk}\" in df2.columns:\n",
    "                    s = df2[f\"close_{tk}\"]\n",
    "                elif \"close\" in df2.columns:\n",
    "                    s = df2[\"close\"]\n",
    "                else:\n",
    "                    return np.full(len(df_), np.nan, dtype=float)\n",
    "        else:\n",
    "            if \"close\" in df_.columns:\n",
    "                s = df_[\"close\"]\n",
    "            else:\n",
    "                return np.full(len(df_), np.nan, dtype=float)\n",
    "        # ensure 1D numeric\n",
    "        return pd.to_numeric(pd.Series(s).to_numpy().ravel(), errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return np.full(len(df_), np.nan, dtype=float)\n",
    "\n",
    "dates_axis = extract_dates(df_used)\n",
    "close_vals = extract_close(df_used, ticker)\n",
    "\n",
    "# Build output DataFrame column-by-column (guaranteed 1-D)\n",
    "pred_c = pd.DataFrame(index=np.arange(n))\n",
    "pred_c[\"date\"]     = dates_axis\n",
    "pred_c[\"ticker\"]   = ticker\n",
    "pred_c[\"close\"]    = close_vals\n",
    "pred_c[\"proba\"]    = p\n",
    "pred_c[\"signal\"]   = sig\n",
    "pred_c[\"tau_used\"] = float(default_tau)\n",
    "\n",
    "# Debug (one-liner shapes)\n",
    "print(\"Shapes:\", {col: pred_c[col].shape for col in pred_c.columns})\n",
    "\n",
    "out_csv_c = (ROOT/\"reports\"/\"demo\"/f\"preds_crypto_{ticker.replace('-','')}.csv\")\n",
    "pred_c.to_csv(out_csv_c, index=False)\n",
    "print(\"Wrote:\", out_csv_c.resolve())\n",
    "print(pred_c.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa00af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md           : True\n",
      "reports/demo        : True\n",
      "CSV: preds_crypto_BTCUSD.csv | bytes: 18911\n",
      "         date   ticker         close     proba  signal  tau_used\n",
      "0  2025-02-13  BTC-USD  96623.867188  0.516461       1      0.45\n",
      "1  2025-02-14  BTC-USD  97508.968750  0.496967       1      0.45\n",
      "CSV: preds_equity_AAPL.csv | bytes: 202195\n",
      "         date ticker      close     proba  signal  tau_used\n",
      "0  2015-02-06   AAPL  26.495501  0.561385       1      0.45\n",
      "1  2015-02-09   AAPL  26.671507  0.542039       1      0.45\n"
     ]
    }
   ],
   "source": [
    "# NB22 — verify outputs\n",
    "import pandas as pd\n",
    "\n",
    "targets = [\n",
    "    \"README.md\",\n",
    "    \"reports/demo\",\n",
    "]\n",
    "for t in targets:\n",
    "    print(f\"{t:20s}:\", (ROOT/t).exists())\n",
    "\n",
    "for f in sorted((ROOT/\"reports\"/\"demo\").glob(\"*.csv\")):\n",
    "    print(\"CSV:\", f.name, \"| bytes:\", f.stat().st_size)\n",
    "    print(pd.read_csv(f).head(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
