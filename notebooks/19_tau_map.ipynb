{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc4e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\.projects\\stock-direction-ml\\stock-direction-ml\\.venv\\Scripts\\python.exe\n",
      "Installing from: requirements.txt\n",
      "✅ Done. If prompted, restart the kernel, then continue with Cell 1.\n"
     ]
    }
   ],
   "source": [
    "# NB19 — Cell 0 (optional): install deps into THIS notebook kernel\n",
    "import sys, subprocess, pathlib\n",
    "print(\"Python:\", sys.executable)\n",
    "req = pathlib.Path(\"requirements.txt\")\n",
    "if not req.exists():\n",
    "    alt = pathlib.Path(\"..\")/\"requirements.txt\"\n",
    "    req = alt if alt.exists() else None\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "if req:\n",
    "    print(\"Installing from:\", req)\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", str(req)])\n",
    "else:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "                           \"numpy\", \"pandas\", \"scikit-learn\", \"joblib\",\n",
    "                           \"matplotlib\", \"pyarrow\"])\n",
    "print(\"✅ Done. If prompted, restart the kernel, then continue with Cell 1.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb17ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root → C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\n",
      "Has data?       True\n",
      "Has artifacts?  True\n"
     ]
    }
   ],
   "source": [
    "# NB19 — Repo root & imports\n",
    "from pathlib import Path\n",
    "import sys, json, numpy as np, pandas as pd\n",
    "\n",
    "def find_repo_root(start: Path, must_have=(\"data\", \"artifacts\")) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if all((cur / m).exists() for m in must_have):\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    if start.name.lower() == \"notebooks\" and all((start.parent / m).exists() for m in must_have):\n",
    "        return start.parent.resolve()\n",
    "    raise FileNotFoundError(\"Repo root not found\")\n",
    "\n",
    "ROOT = find_repo_root(Path.cwd())\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "print(\"Repo root →\", ROOT)\n",
    "print(\"Has data?      \", (ROOT/\"data\").exists())\n",
    "print(\"Has artifacts? \", (ROOT/\"artifacts\").exists())\n",
    "\n",
    "from app.lib_artifacts import load_artifacts\n",
    "from app.lib_features  import make_dataset\n",
    "from app.lib_eval      import predict_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d934fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2686 | has 'ticker'? True\n",
      "Default τ from artifacts: 0.59 | existing tau_map entries: 0\n"
     ]
    }
   ],
   "source": [
    "# NB19 — Load df_nb02.* and artifacts (equities)\n",
    "if (ROOT/\"data/df_nb02.csv\").exists():\n",
    "    df = pd.read_csv(ROOT/\"data/df_nb02.csv\")\n",
    "elif (ROOT/\"data/df_nb02.parquet\").exists():\n",
    "    df = pd.read_parquet(ROOT/\"data/df_nb02.parquet\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing data/df_nb02.* in data/\")\n",
    "\n",
    "# unify/parse date column if present\n",
    "for c in [\"date\",\"Date\",\"timestamp\",\"ts\"]:\n",
    "    if c in df.columns:\n",
    "        try: df[c] = pd.to_datetime(df[c])\n",
    "        except: pass\n",
    "        if c != \"date\": df[\"date\"] = df[c]\n",
    "        break\n",
    "\n",
    "feature_list, scaler, model, tau_art, tau_map_existing = load_artifacts(\"equity\")\n",
    "print(\"Rows:\", len(df), \"| has 'ticker'?\", \"ticker\" in df.columns)\n",
    "print(\"Default τ from artifacts:\", tau_art, \"| existing tau_map entries:\", len(tau_map_existing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a7a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB19 — Helpers\n",
    "from sklearn.metrics import f1_score, roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    "\n",
    "def safe(fn, *a):\n",
    "    try: return float(fn(*a))\n",
    "    except Exception: return float(\"nan\")\n",
    "\n",
    "def final_equity(retn, sig, fee_bps=5):\n",
    "    flips = np.zeros_like(sig)\n",
    "    if len(flips)>1: flips[1:] = (sig[1:] != sig[:-1]).astype(int)\n",
    "    fee = flips * (fee_bps/10000.0)\n",
    "    eq  = np.cumprod(1 + (retn*sig - fee))\n",
    "    return float(eq[-1]) if len(eq) else float(\"nan\")\n",
    "\n",
    "def sweep_tau(y, p, retn, fee_bps=5, grid=np.linspace(0.05, 0.95, 91)):\n",
    "    f1s, finals = [], []\n",
    "    for t in grid:\n",
    "        sig = (p >= t).astype(int)\n",
    "        f1s.append(safe(f1_score, y, sig))\n",
    "        finals.append(final_equity(retn, sig, fee_bps))\n",
    "    best_f1_tau = float(grid[int(np.nanargmax(f1s))]) if np.any(~np.isnan(f1s)) else None\n",
    "    best_eq_tau = float(grid[int(np.nanargmax(finals))])\n",
    "    return best_f1_tau, best_eq_tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf6c0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker  rows  used_rows  features       auc        ap     brier   logloss  \\\n",
      "0   AAPL  2686       2686        16  0.521484  0.549973  0.250372  0.693868   \n",
      "\n",
      "   best_f1_tau  best_eq_tau  chosen_tau  \n",
      "0         0.15         0.45        0.45  \n"
     ]
    }
   ],
   "source": [
    "# NB19 — Compute per-ticker τ (equities)\n",
    "results = []\n",
    "tau_map = dict(tau_map_existing)  # start from existing\n",
    "\n",
    "tickers = [None] if \"ticker\" not in df.columns else sorted(df[\"ticker\"].dropna().unique().tolist())\n",
    "for tk in tickers:\n",
    "    sdf = df if tk is None else df.loc[df[\"ticker\"] == tk].copy()\n",
    "    if tk is not None and len(sdf) < 80:   # skip very short series\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        X, y, retn, idx, used_cols = make_dataset(sdf, feature_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Skip {tk}: {e}\")\n",
    "        continue\n",
    "    if len(X)==0 or y is None:\n",
    "        print(f\"Skip {tk}: no usable rows/labels\")\n",
    "        continue\n",
    "\n",
    "    p = np.clip(predict_proba(model, scaler.transform(X)), 1e-6, 1-1e-6)\n",
    "\n",
    "    auc   = safe(roc_auc_score, y, p)\n",
    "    ap    = safe(average_precision_score, y, p)\n",
    "    brier = safe(brier_score_loss, y, p)\n",
    "    ll    = safe(log_loss, y, p)\n",
    "\n",
    "    f1_tau, eq_tau = sweep_tau(y, p, retn, fee_bps=5)\n",
    "    chosen_tau = eq_tau   # choose by final equity; switch to f1_tau if you prefer\n",
    "\n",
    "    key = tk if tk is not None else \"_GLOBAL\"\n",
    "    tau_map[key] = float(chosen_tau)\n",
    "\n",
    "    results.append(dict(\n",
    "        ticker=key, rows=len(sdf), used_rows=len(p), features=len(used_cols),\n",
    "        auc=auc, ap=ap, brier=brier, logloss=ll,\n",
    "        best_f1_tau=f1_tau, best_eq_tau=eq_tau, chosen_tau=chosen_tau\n",
    "    ))\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(by=[\"ticker\"]).reset_index(drop=True)\n",
    "print(res_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a65893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote τ map: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\artifacts\\tau_map.json\n",
      "Wrote metrics CSV: C:\\.projects\\stock-direction-ml\\stock-direction-ml\\notebooks\\reports\\ticker_metrics.csv\n",
      "{\n",
      "  \"AAPL\": 0.4499999999999999\n",
      "}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# NB19 — Write artifacts/tau_map.json and reports/ticker_metrics.csv\n",
    "out_map = ROOT/\"artifacts\"/\"tau_map.json\"\n",
    "out_map.write_text(json.dumps(tau_map, indent=2), encoding=\"utf-8\")\n",
    "print(\"Wrote τ map:\", out_map.resolve())\n",
    "\n",
    "reports_dir = ROOT/\"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = reports_dir/\"ticker_metrics.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(\"Wrote metrics CSV:\", out_csv.resolve())\n",
    "\n",
    "# show first lines of tau_map\n",
    "print((out_map.read_text(encoding=\"utf-8\")[:600] + \"\\n...\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973c731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau_map keys: ['AAPL'] \n",
      "\n",
      "Next:\n",
      "  1) Run the app and verify defaults:\n",
      "     streamlit run app/streamlit_app.py\n",
      "     • Pick a ticker present in tau_map.json → τ slider should default to that value.\n",
      "  2) Commit:\n",
      "     git add artifacts/tau_map.json reports/ticker_metrics.csv\n",
      "     git commit -m \"nb19: seed per-ticker tau_map + metrics\"\n",
      "     git push\n"
     ]
    }
   ],
   "source": [
    "# NB19 — Quick check + instructions\n",
    "print(\"tau_map keys:\", list(tau_map.keys())[:10], \"...\" if len(tau_map)>10 else \"\")\n",
    "print(\"\\nNext:\")\n",
    "print(\"  1) Run the app and verify defaults:\")\n",
    "print(\"     streamlit run app/streamlit_app.py\")\n",
    "print(\"     • Pick a ticker present in tau_map.json → τ slider should default to that value.\")\n",
    "print(\"  2) Commit:\")\n",
    "print(\"     git add artifacts/tau_map.json reports/ticker_metrics.csv\")\n",
    "print(\"     git commit -m \\\"nb19: seed per-ticker tau_map + metrics\\\"\")\n",
    "print(\"     git push\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
