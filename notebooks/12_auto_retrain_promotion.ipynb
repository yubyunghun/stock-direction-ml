{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c24efa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB12 config → run_id: 2025-10-23T004239Z | fee_bps: 5.0 | target_cov: 0.2\n"
     ]
    }
   ],
   "source": [
    "# NB12 — Auto-Retrain & Promotion\n",
    "\n",
    "import json, os, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
    "from joblib import dump, load\n",
    "\n",
    "# Optional XGBoost (baseline-only; promotion still based on LR unless you flip a flag)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "DATA = Path(\"data\"); ART = Path(\"artifacts\"); FIG = Path(\"reports/figures\")\n",
    "for p in [DATA, ART, FIG]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Retrain policy\n",
    "SEED        = 42\n",
    "FEE_BPS     = 5.0             # used in Sharpe-based threshold tuning\n",
    "TARGET_COV  = 0.20            # coverage target if you prefer quantile threshold\n",
    "SPLIT       = (0.60, 0.20, 0.20)  # train/val/test (time-ordered)\n",
    "PROMOTE_RULE = dict(\n",
    "    min_auc_gain = 0.00,      # require >= this AUC gain vs prod on TEST\n",
    "    min_sharpe   = 0.00       # require new Sharpe >= this on TEST (>=0.0 means non-negative)\n",
    ")\n",
    "\n",
    "RUN_ID = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H%M%SZ\")\n",
    "print(\"NB12 config → run_id:\", RUN_ID, \"| fee_bps:\", FEE_BPS, \"| target_cov:\", TARGET_COV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4260f541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows/Features: 2686 / 16\n",
      "Splits: (1611, 22) (537, 22) (538, 22)\n",
      "Pos rate (train/val/test): 0.529 0.514 0.548\n",
      "Span: 2015-02-06 → 2025-10-10\n"
     ]
    }
   ],
   "source": [
    "# Load df (CSV/Parquet) and features from ART\n",
    "df_path = DATA/\"df_nb02.parquet\" if (DATA/\"df_nb02.parquet\").exists() else DATA/\"df_nb02.csv\"\n",
    "assert df_path.exists(), \"df_nb02 not found — run earlier notebooks\"\n",
    "df = pd.read_parquet(df_path) if df_path.suffix==\".parquet\" else pd.read_csv(df_path, parse_dates=[\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "feat_cols = json.loads((ART/\"feature_list.json\").read_text(encoding=\"utf-8\"))\n",
    "feat_cols = [c for c in feat_cols if c in df.columns]  # intersect\n",
    "assert feat_cols, \"feature_list.json produced empty feature set against df\"\n",
    "\n",
    "# Label: use existing y or derive next-day up\n",
    "if \"y\" not in df.columns:\n",
    "    if \"ret1\" in df.columns:\n",
    "        df[\"y\"] = (df[\"ret1\"].shift(-1) > 0).astype(int)\n",
    "    elif \"close\" in df.columns:\n",
    "        df[\"y\"] = (df[\"close\"].pct_change().shift(-1) > 0).astype(int)\n",
    "    else:\n",
    "        raise RuntimeError(\"No label present and cannot derive from prices.\")\n",
    "\n",
    "df = df.sort_values(\"date\").dropna(subset=[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "n = len(df); n_tr = int(SPLIT[0]*n); n_va = int(SPLIT[1]*n)\n",
    "df_tr = df.iloc[:n_tr].copy()\n",
    "df_va = df.iloc[n_tr:n_tr+n_va].copy()\n",
    "df_te = df.iloc[n_tr+n_va:].copy()\n",
    "\n",
    "X_tr, y_tr = df_tr[feat_cols].to_numpy(), df_tr[\"y\"].astype(int).to_numpy()\n",
    "X_va, y_va = df_va[feat_cols].to_numpy(), df_va[\"y\"].astype(int).to_numpy()\n",
    "X_te, y_te = df_te[feat_cols].to_numpy(), df_te[\"y\"].astype(int).to_numpy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "Xs_tr = scaler.transform(X_tr)\n",
    "Xs_va = scaler.transform(X_va)\n",
    "Xs_te = scaler.transform(X_te)\n",
    "\n",
    "print(\"Rows/Features:\", n, \"/\", len(feat_cols))\n",
    "print(\"Splits:\", df_tr.shape, df_va.shape, df_te.shape)\n",
    "print(\"Pos rate (train/val/test):\", y_tr.mean().round(3), y_va.mean().round(3), y_te.mean().round(3))\n",
    "print(\"Span:\", df[\"date\"].min().date(), \"→\", df[\"date\"].max().date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19272462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>Brier</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>PosRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>val</td>\n",
       "      <td>0.458104</td>\n",
       "      <td>0.487851</td>\n",
       "      <td>0.262018</td>\n",
       "      <td>0.718572</td>\n",
       "      <td>0.513966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>test</td>\n",
       "      <td>0.479180</td>\n",
       "      <td>0.520515</td>\n",
       "      <td>0.257710</td>\n",
       "      <td>0.708665</td>\n",
       "      <td>0.548327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>val</td>\n",
       "      <td>0.532317</td>\n",
       "      <td>0.554066</td>\n",
       "      <td>0.282554</td>\n",
       "      <td>0.782340</td>\n",
       "      <td>0.513966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>test</td>\n",
       "      <td>0.461924</td>\n",
       "      <td>0.526903</td>\n",
       "      <td>0.300178</td>\n",
       "      <td>0.810264</td>\n",
       "      <td>0.548327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model split       AUC    PR_AUC     Brier   LogLoss   PosRate\n",
       "0    LR   val  0.458104  0.487851  0.262018  0.718572  0.513966\n",
       "1    LR  test  0.479180  0.520515  0.257710  0.708665  0.548327\n",
       "2   XGB   val  0.532317  0.554066  0.282554  0.782340  0.513966\n",
       "3   XGB  test  0.461924  0.526903  0.300178  0.810264  0.548327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def metric_block(y, p):\n",
    "    p = np.clip(np.asarray(p), 1e-15, 1-1e-15)\n",
    "    return dict(\n",
    "        AUC=float(roc_auc_score(y, p)) if len(np.unique(y))>1 else np.nan,\n",
    "        PR_AUC=float(average_precision_score(y, p)),\n",
    "        Brier=float(brier_score_loss(y, p)),\n",
    "        LogLoss=float(log_loss(y, p)),\n",
    "        PosRate=float(np.mean(y)),\n",
    "    )\n",
    "\n",
    "candidates = {}\n",
    "\n",
    "# Logistic Regression (standardized)\n",
    "lr = LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED)\n",
    "lr.fit(Xs_tr, y_tr)\n",
    "p_va_lr = lr.predict_proba(Xs_va)[:,1]\n",
    "p_te_lr = lr.predict_proba(Xs_te)[:,1]\n",
    "candidates[\"LR\"] = dict(model=lr, scaler=scaler, p_va=p_va_lr, p_te=p_te_lr, std=True)\n",
    "\n",
    "# Optional XGB (often without standardization)\n",
    "if HAS_XGB:\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=400, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "        random_state=SEED, n_jobs=0, objective=\"binary:logistic\", eval_metric=\"logloss\"\n",
    "    )\n",
    "    xgb.fit(X_tr, y_tr)\n",
    "    p_va_xgb = xgb.predict_proba(X_va)[:,1]\n",
    "    p_te_xgb = xgb.predict_proba(X_te)[:,1]\n",
    "    candidates[\"XGB\"] = dict(model=xgb, scaler=None, p_va=p_va_xgb, p_te=p_te_xgb, std=False)\n",
    "\n",
    "rows = []\n",
    "for name, d in candidates.items():\n",
    "    rows += [\n",
    "        dict(model=name, split=\"val\", **metric_block(y_va, d[\"p_va\"])),\n",
    "        dict(model=name, split=\"test\", **metric_block(y_te, d[\"p_te\"])),\n",
    "    ]\n",
    "valtest = pd.DataFrame(rows)\n",
    "display(valtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "549f79c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>thr</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>CAGR</th>\n",
       "      <th>total_return</th>\n",
       "      <th>max_drawdown</th>\n",
       "      <th>vol_annual</th>\n",
       "      <th>AUC_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>-0.835022</td>\n",
       "      <td>-0.074592</td>\n",
       "      <td>-0.152531</td>\n",
       "      <td>-0.187996</td>\n",
       "      <td>0.08933</td>\n",
       "      <td>0.479180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.561802</td>\n",
       "      <td>-0.906763</td>\n",
       "      <td>-0.119593</td>\n",
       "      <td>-0.238090</td>\n",
       "      <td>-0.315987</td>\n",
       "      <td>0.13189</td>\n",
       "      <td>0.461924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model       thr    Sharpe      CAGR  total_return  max_drawdown  vol_annual  \\\n",
       "0    LR  0.559691 -0.835022 -0.074592     -0.152531     -0.187996     0.08933   \n",
       "1   XGB  0.561802 -0.906763 -0.119593     -0.238090     -0.315987     0.13189   \n",
       "\n",
       "   AUC_test  \n",
       "0  0.479180  \n",
       "1  0.461924  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FEE = FEE_BPS/10000.0\n",
    "\n",
    "def sharpe_from(p, ret_next, thr):\n",
    "    pos = (p >= thr).astype(int)\n",
    "    flips = np.abs(np.diff(np.r_[0, pos]))>0\n",
    "    r = pos*ret_next - flips*FEE\n",
    "    r = pd.Series(r).fillna(0.0)\n",
    "    if r.std()==0: return 0.0\n",
    "    return (r.mean()/r.std()) * np.sqrt(252)\n",
    "\n",
    "def tune_thr_on_val(p_val, ret_next_val, grid=None, target_cov=None):\n",
    "    if target_cov is not None:\n",
    "        q = 1.0 - float(target_cov)\n",
    "        return float(np.quantile(p_val, q))\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 181)\n",
    "    scores = [(t, sharpe_from(p_val, ret_next_val, t)) for t in grid]\n",
    "    return max(scores, key=lambda x: x[1])[0]\n",
    "\n",
    "# Build ret_next on val/test from close if missing\n",
    "def next_returns(df_):\n",
    "    if \"ret_next\" in df_.columns:\n",
    "        return df_[\"ret_next\"].to_numpy()\n",
    "    if \"close\" in df_.columns:\n",
    "        return pd.Series(df_[\"close\"]).pct_change().shift(-1).to_numpy()\n",
    "    raise KeyError(\"Need ret_next or close to compute returns.\")\n",
    "\n",
    "ret_va = next_returns(df_va)\n",
    "ret_te = next_returns(df_te)\n",
    "\n",
    "bt_rows = []\n",
    "for name, d in candidates.items():\n",
    "    thr = tune_thr_on_val(d[\"p_va\"], ret_va, target_cov=None if TARGET_COV is None else TARGET_COV)\n",
    "    pos_te = (d[\"p_te\"] >= thr).astype(int)\n",
    "    flips  = (np.abs(np.diff(np.r_[0, pos_te]))>0)\n",
    "    r_te   = pos_te*ret_te - flips*FEE\n",
    "    r_te   = pd.Series(r_te).fillna(0.0)\n",
    "    eq     = (1 + r_te).cumprod()\n",
    "    cagr   = (1 + r_te).prod() ** (252/max(len(r_te),1)) - 1\n",
    "    vol    = r_te.std() * np.sqrt(252)\n",
    "    sharpe = (cagr/vol) if vol>0 else np.nan\n",
    "    mdd    = (eq/eq.cummax() - 1).min()\n",
    "    bt_rows.append(dict(\n",
    "        model=name, thr=float(thr),\n",
    "        Sharpe=float(sharpe), CAGR=float(cagr), total_return=float(eq.iloc[-1]-1),\n",
    "        max_drawdown=float(mdd), vol_annual=float(vol),\n",
    "        AUC_test=float(roc_auc_score(y_te, d[\"p_te\"])) if len(np.unique(y_te))>1 else np.nan\n",
    "    ))\n",
    "\n",
    "bt = pd.DataFrame(bt_rows)\n",
    "display(bt.sort_values(\"Sharpe\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25c5ff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production metrics (recomputed on current TEST):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'PROD',\n",
       " 'thr': 0.59,\n",
       " 'AUC_test': 0.47899839575922437,\n",
       " 'Sharpe': -0.8414327300269396,\n",
       " 'CAGR': -0.06994977516750267,\n",
       " 'total_return': -0.1434284062079053,\n",
       " 'max_drawdown': -0.16464420453018258,\n",
       " 'vol_annual': 0.08313174977786178}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load current prod model/scaler & compute TEST AUC + backtest\n",
    "prod_lr = load(ART/\"lr.joblib\")\n",
    "prod_scaler = load(ART/\"scaler.joblib\") if (ART/\"scaler.joblib\").exists() else None\n",
    "prod_thr = None\n",
    "thr_json_p = ART/\"threshold.json\"\n",
    "if thr_json_p.exists():\n",
    "    tj = json.loads(thr_json_p.read_text(encoding=\"utf-8\"))\n",
    "    if \"threshold\" in tj: prod_thr = float(tj[\"threshold\"])\n",
    "    elif \"LR\" in tj and isinstance(tj[\"LR\"], dict) and \"tau\" in tj[\"LR\"]: prod_thr = float(tj[\"LR\"][\"tau\"])\n",
    "    elif \"tau\" in tj: prod_thr = float(tj[\"tau\"])\n",
    "\n",
    "X_te_prod = prod_scaler.transform(X_te) if prod_scaler is not None else X_te\n",
    "p_te_prod = prod_lr.predict_proba(X_te_prod)[:,1]\n",
    "auc_prod  = float(roc_auc_score(y_te, p_te_prod)) if len(np.unique(y_te))>1 else np.nan\n",
    "\n",
    "# Backtest with prod threshold (fallback: quantile @ 1-TARGET_COV)\n",
    "thr_prod = prod_thr if prod_thr is not None else float(np.quantile(p_te_prod, 1.0 - TARGET_COV))\n",
    "pos_te   = (p_te_prod >= thr_prod).astype(int)\n",
    "flips    = (np.abs(np.diff(np.r_[0, pos_te]))>0)\n",
    "r_te     = pos_te*ret_te - flips*(FEE_BPS/10000.0)\n",
    "r_te     = pd.Series(r_te).fillna(0.0)\n",
    "eq       = (1+r_te).cumprod()\n",
    "cagr_p   = (1+r_te).prod() ** (252/max(len(r_te),1)) - 1\n",
    "vol_p    = r_te.std()*np.sqrt(252)\n",
    "shp_p    = (cagr_p/vol_p) if vol_p>0 else np.nan\n",
    "mdd_p    = (eq/eq.cummax() - 1).min()\n",
    "\n",
    "prod_metrics = dict(model=\"PROD\", thr=float(thr_prod), AUC_test=auc_prod,\n",
    "                    Sharpe=float(shp_p), CAGR=float(cagr_p), total_return=float(eq.iloc[-1]-1),\n",
    "                    max_drawdown=float(mdd_p), vol_annual=float(vol_p))\n",
    "print(\"Production metrics (recomputed on current TEST):\")\n",
    "prod_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4aaccfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promote': False,\n",
       " 'reason': 'fails_guardrails',\n",
       " 'new': {'model': 'LR',\n",
       "  'thr': 0.5596911486813771,\n",
       "  'Sharpe': -0.8350221076586054,\n",
       "  'CAGR': -0.0745922147354845,\n",
       "  'total_return': -0.15253075843443376,\n",
       "  'max_drawdown': -0.18799590989508974,\n",
       "  'vol_annual': 0.08932962858269754,\n",
       "  'AUC_test': 0.47917974471646785},\n",
       " 'prod': {'model': 'PROD',\n",
       "  'thr': 0.59,\n",
       "  'AUC_test': 0.47899839575922437,\n",
       "  'Sharpe': -0.8414327300269396,\n",
       "  'CAGR': -0.06994977516750267,\n",
       "  'total_return': -0.1434284062079053,\n",
       "  'max_drawdown': -0.16464420453018258,\n",
       "  'vol_annual': 0.08313174977786178}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick best candidate by Sharpe (you can choose AUC instead)\n",
    "new_best = bt.sort_values([\"Sharpe\",\"AUC_test\"], ascending=[False, False]).head(1).iloc[0].to_dict()\n",
    "\n",
    "promote = True\n",
    "# AUC guardrail\n",
    "if not (np.isnan(new_best[\"AUC_test\"]) or np.isnan(prod_metrics[\"AUC_test\"])):\n",
    "    if new_best[\"AUC_test\"] < prod_metrics[\"AUC_test\"] + PROMOTE_RULE[\"min_auc_gain\"]:\n",
    "        promote = False\n",
    "# Sharpe guardrail\n",
    "if not np.isnan(new_best[\"Sharpe\"]):\n",
    "    if new_best[\"Sharpe\"] < PROMOTE_RULE[\"min_sharpe\"]:\n",
    "        promote = False\n",
    "\n",
    "decision = dict(promote=promote, reason=\"meets_guardrails\" if promote else \"fails_guardrails\",\n",
    "                new=new_best, prod=prod_metrics)\n",
    "decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "176b19fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT PROMOTED ⚠️  → Kept current production artifacts.\n"
     ]
    }
   ],
   "source": [
    "if decision[\"promote\"]:\n",
    "    name = list(candidates.keys())[0] if decision[\"new\"][\"model\"]==\"LR\" else decision[\"new\"][\"model\"]\n",
    "    cand = candidates[decision[\"new\"][\"model\"]]\n",
    "    model = cand[\"model\"]; sc = cand[\"scaler\"]\n",
    "\n",
    "    # Versioned filenames\n",
    "    vtag = RUN_ID\n",
    "    lr_new = ART/f\"lr_{vtag}.joblib\"\n",
    "    sc_new = ART/f\"scaler_{vtag}.joblib\"\n",
    "    thr_new = ART/f\"threshold_{vtag}.json\"\n",
    "    bs_new  = ART/f\"backtest_summary_{vtag}.json\"\n",
    "\n",
    "    dump(model, lr_new)\n",
    "    if sc is not None:\n",
    "        dump(sc, sc_new)\n",
    "    json.dump({\"threshold\": float(decision[\"new\"][\"thr\"]), \"policy\": \"SharpeValOptim\"},\n",
    "              open(thr_new,\"w\",encoding=\"utf-8\"), indent=2)\n",
    "    json.dump({\n",
    "        \"fee_bps\": FEE_BPS, \"slippage_bps\": 0.0, \"allow_short\": False,\n",
    "        \"models\": {decision[\"new\"][\"model\"]: {\n",
    "            \"tau\": float(decision[\"new\"][\"thr\"]), \"Sharpe\": float(decision[\"new\"][\"Sharpe\"]),\n",
    "            \"CAGR\": float(decision[\"new\"][\"CAGR\"]), \"max_drawdown\": float(decision[\"new\"][\"max_drawdown\"]),\n",
    "            \"total_return\": float(decision[\"new\"][\"total_return\"]), \"vol_annual\": float(decision[\"new\"][\"vol_annual\"]),\n",
    "            \"AUC_test\": float(decision[\"new\"][\"AUC_test\"])\n",
    "        }}\n",
    "    }, open(bs_new,\"w\",encoding=\"utf-8\"), indent=2)\n",
    "\n",
    "    # Atomically update \"current\" pointers\n",
    "    shutil.copy2(lr_new, ART/\"lr.joblib\")\n",
    "    if sc is not None:\n",
    "        shutil.copy2(sc_new, ART/\"scaler.joblib\")\n",
    "    shutil.copy2(thr_new, ART/\"threshold.json\")\n",
    "    shutil.copy2(bs_new, ART/\"backtest_summary.json\")\n",
    "\n",
    "    # Update registry\n",
    "    reg_p = ART/\"model_registry.json\"\n",
    "    if reg_p.exists():\n",
    "        reg = json.loads(reg_p.read_text(encoding=\"utf-8\"))\n",
    "        if not isinstance(reg, list): reg = [reg]\n",
    "    else:\n",
    "        reg = []\n",
    "    reg.append({\n",
    "        \"version\": vtag,\n",
    "        \"promoted_utc\": RUN_ID,\n",
    "        \"model\": decision[\"new\"][\"model\"],\n",
    "        \"n_features\": len(feat_cols),\n",
    "        \"thr\": float(decision[\"new\"][\"thr\"]),\n",
    "        \"metrics_test\": {\n",
    "            \"AUC\": float(decision[\"new\"][\"AUC_test\"]),\n",
    "            \"Sharpe\": float(decision[\"new\"][\"Sharpe\"]),\n",
    "            \"CAGR\": float(decision[\"new\"][\"CAGR\"]),\n",
    "            \"total_return\": float(decision[\"new\"][\"total_return\"]),\n",
    "            \"max_drawdown\": float(decision[\"new\"][\"max_drawdown\"]),\n",
    "            \"vol_annual\": float(decision[\"new\"][\"vol_annual\"]),\n",
    "        }\n",
    "    })\n",
    "    reg_p.write_text(json.dumps(reg, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"PROMOTED ✅  → Updated lr.joblib / scaler.joblib / threshold.json / backtest_summary.json\")\n",
    "else:\n",
    "    print(\"NOT PROMOTED ⚠️  → Kept current production artifacts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b10b58ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB12 Verifier ===\n",
      "Artifacts exist: {'lr.joblib': True, 'threshold.json': True, 'backtest_summary.json': True}\n",
      "{'active_tau': 0.59, 'model_keys': ['LR'], 'fee_bps': 5.0}\n",
      "VERDICT: PASS ✅\n"
     ]
    }
   ],
   "source": [
    "print(\"=== NB12 Verifier ===\")\n",
    "need = [ART/\"lr.joblib\", ART/\"threshold.json\", ART/\"backtest_summary.json\"]\n",
    "exists = {p.name: (p.exists() and p.stat().st_size > 0) for p in need}\n",
    "print(\"Artifacts exist:\", exists)\n",
    "\n",
    "# Show who is active now\n",
    "thr = json.loads((ART/\"threshold.json\").read_text(encoding=\"utf-8\"))\n",
    "bs  = json.loads((ART/\"backtest_summary.json\").read_text(encoding=\"utf-8\"))\n",
    "active_tau = thr.get(\"threshold\") or thr.get(\"tau\") or thr.get(\"LR\",{}).get(\"tau\")\n",
    "\n",
    "show = dict(\n",
    "    active_tau=active_tau,\n",
    "    model_keys=list(bs.get(\"models\", {}).keys()),\n",
    "    fee_bps=bs.get(\"fee_bps\"),\n",
    ")\n",
    "print(show)\n",
    "print(\"VERDICT:\", \"PASS ✅\" if all(exists.values()) else \"CHECK ⚠️\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b62c238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged decision → data/promotion_decisions.csv\n",
      "Snapshot       → artifacts/promotion_decision_2025-10-23T00-42-40.234682+00-00.json\n"
     ]
    }
   ],
   "source": [
    "# NB12 — archive decision (even when NOT PROMOTED)\n",
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "ART, DATA = Path(\"artifacts\"), Path(\"data\")\n",
    "ART.mkdir(exist_ok=True, parents=True); DATA.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Load prior decision object from Cell 6 if still in memory; else read a minimal one\n",
    "try:\n",
    "    _decision = decision  # from Cell 6\n",
    "except NameError:\n",
    "    _decision = {\"promote\": False, \"reason\": \"unknown\"}\n",
    "\n",
    "entry = {\n",
    "    \"ts_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"promote\": bool(_decision.get(\"promote\", False)),\n",
    "    \"reason\": _decision.get(\"reason\"),\n",
    "    \"new\": _decision.get(\"new\", {}),\n",
    "    \"prod\": _decision.get(\"prod\", {}),\n",
    "}\n",
    "\n",
    "# Append to a CSV log\n",
    "log_p = DATA/\"promotion_decisions.csv\"\n",
    "pd.DataFrame([{\n",
    "    \"ts_utc\": entry[\"ts_utc\"],\n",
    "    \"promote\": entry[\"promote\"],\n",
    "    \"reason\": entry[\"reason\"],\n",
    "    \"new_auc\": entry[\"new\"].get(\"AUC_test\"),\n",
    "    \"new_sharpe\": entry[\"new\"].get(\"Sharpe\"),\n",
    "    \"new_thr\": entry[\"new\"].get(\"thr\"),\n",
    "    \"prod_auc\": entry[\"prod\"].get(\"AUC_test\"),\n",
    "    \"prod_sharpe\": entry[\"prod\"].get(\"Sharpe\"),\n",
    "    \"prod_thr\": entry[\"prod\"].get(\"thr\"),\n",
    "}]).to_csv(log_p, mode=\"a\", header=not log_p.exists(), index=False)\n",
    "\n",
    "# Also write a JSON snapshot\n",
    "snap_p = ART/f\"promotion_decision_{entry['ts_utc'].replace(':','-')}.json\"\n",
    "snap_p.write_text(json.dumps(entry, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Logged decision →\", log_p.as_posix())\n",
    "print(\"Snapshot       →\", snap_p.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec953295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log exists: True | size: 563\n",
      "Log rows: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_utc</th>\n",
       "      <th>promote</th>\n",
       "      <th>reason</th>\n",
       "      <th>new_auc</th>\n",
       "      <th>new_sharpe</th>\n",
       "      <th>new_thr</th>\n",
       "      <th>prod_auc</th>\n",
       "      <th>prod_sharpe</th>\n",
       "      <th>prod_thr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-23T00:39:11.135467+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>fails_guardrails</td>\n",
       "      <td>0.47918</td>\n",
       "      <td>-0.835022</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>0.478998</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-23T00:41:22.778234+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>fails_guardrails</td>\n",
       "      <td>0.47918</td>\n",
       "      <td>-0.835022</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>0.478998</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-23T00:42:40.234682+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>fails_guardrails</td>\n",
       "      <td>0.47918</td>\n",
       "      <td>-0.835022</td>\n",
       "      <td>0.559691</td>\n",
       "      <td>0.478998</td>\n",
       "      <td>-0.841433</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ts_utc  promote            reason  new_auc  \\\n",
       "0  2025-10-23T00:39:11.135467+00:00    False  fails_guardrails  0.47918   \n",
       "1  2025-10-23T00:41:22.778234+00:00    False  fails_guardrails  0.47918   \n",
       "2  2025-10-23T00:42:40.234682+00:00    False  fails_guardrails  0.47918   \n",
       "\n",
       "   new_sharpe   new_thr  prod_auc  prod_sharpe  prod_thr  \n",
       "0   -0.835022  0.559691  0.478998    -0.841433      0.59  \n",
       "1   -0.835022  0.559691  0.478998    -0.841433      0.59  \n",
       "2   -0.835022  0.559691  0.478998    -0.841433      0.59  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Promote counts: {False: 3}\n",
      "\n",
      "Latest snapshot: promotion_decision_2025-10-23T00-42-40.234682+00-00.json\n",
      "{'ts_utc': '2025-10-23T00:42:40.234682+00:00', 'promote': False, 'reason': 'fails_guardrails', 'new': {'model': 'LR', 'thr': 0.5596911486813771, 'Sharpe': -0.8350221076586054, 'CAGR': -0.0745922147354845, 'total_return': -0.15253075843443376, 'max_drawdown': -0.18799590989508974, 'vol_annual': 0.08932962858269754, 'AUC_test': 0.47917974471646785}, 'prod': {'model': 'PROD', 'thr': 0.59, 'AUC_test': 0.47899839575922437, 'Sharpe': -0.8414327300269396, 'CAGR': -0.06994977516750267, 'total_return': -0.1434284062079053, 'max_drawdown': -0.16464420453018258, 'vol_annual': 0.08313174977786178}}\n"
     ]
    }
   ],
   "source": [
    "# NB12 — verify promotion decision log & latest snapshot\n",
    "from pathlib import Path\n",
    "import json, pandas as pd\n",
    "\n",
    "ART, DATA = Path(\"artifacts\"), Path(\"data\")\n",
    "log_p = DATA/\"promotion_decisions.csv\"\n",
    "\n",
    "print(\"Log exists:\", log_p.exists(), \"| size:\", log_p.stat().st_size if log_p.exists() else 0)\n",
    "if log_p.exists():\n",
    "    log = pd.read_csv(log_p)\n",
    "    print(\"Log rows:\", len(log))\n",
    "    display(log.tail(5))\n",
    "    print(\"\\nPromote counts:\", log[\"promote\"].value_counts(dropna=False).to_dict())\n",
    "\n",
    "# Show latest JSON snapshot\n",
    "snaps = list(ART.glob(\"promotion_decision_*.json\"))\n",
    "if snaps:\n",
    "    latest = max(snaps, key=lambda p: p.stat().st_mtime)\n",
    "    print(\"\\nLatest snapshot:\", latest.name)\n",
    "    snap = json.loads(latest.read_text(encoding=\"utf-8\"))\n",
    "    print(snap)\n",
    "else:\n",
    "    print(\"\\nNo JSON snapshots found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
