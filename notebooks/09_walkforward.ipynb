{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4097d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NB9: imports & run config ---\n",
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Repro + IO\n",
    "RNG = 42\n",
    "np.random.seed(RNG)\n",
    "DATA_DIR = Path(\"data\")\n",
    "ART_DIR  = Path(\"artifacts\")\n",
    "FIG_DIR  = Path(\"reports/figures\")\n",
    "for p in [DATA_DIR, ART_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Costs & threshold (τ from artifacts/threshold.json if available)\n",
    "FEE_BPS = 5.0\n",
    "SLIPPAGE_BPS = 0.0\n",
    "TAU = 0.59\n",
    "thr_p = ART_DIR / \"threshold.json\"\n",
    "if thr_p.exists():\n",
    "    try:\n",
    "        tj = json.loads(thr_p.read_text(encoding=\"utf-8\"))\n",
    "        if isinstance(tj, dict):\n",
    "            if \"threshold\" in tj:             TAU = float(tj[\"threshold\"])\n",
    "            elif \"LR\" in tj and \"tau\" in tj[\"LR\"]: TAU = float(tj[\"LR\"][\"tau\"])\n",
    "            elif \"tau\" in tj:                 TAU = float(tj[\"tau\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"Using threshold τ = {TAU} | Fee bps = {FEE_BPS} | Slippage bps = {SLIPPAGE_BPS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load df_nb02 (robust) & ensure label 'y' ---\n",
    "df_path = DATA_DIR/\"df_nb02.parquet\" if (DATA_DIR/\"df_nb02.parquet\").exists() else DATA_DIR/\"df_nb02.csv\"\n",
    "df = pd.read_parquet(df_path) if df_path.suffix == \".parquet\" else pd.read_csv(df_path, parse_dates=[\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "label_col = next((c for c in [\"y\",\"target\",\"label\",\"y_next_up\"] if c in df.columns), None)\n",
    "if label_col is None:\n",
    "    if \"ret1\" in df.columns:\n",
    "        df[\"y\"] = (df[\"ret1\"].shift(-1) > 0).astype(int)\n",
    "    elif \"close\" in df.columns:\n",
    "        df[\"y\"] = (pd.Series(df[\"close\"]).pct_change().shift(-1) > 0).astype(int)\n",
    "    else:\n",
    "        raise RuntimeError(\"No label & cannot derive from ret1/close.\")\n",
    "elif label_col != \"y\":\n",
    "    df[\"y\"] = df[label_col].astype(int)\n",
    "\n",
    "print(f\"Rows/Features: {len(df)} / {df.shape[1]-1}\")\n",
    "print(f\"Span: {df['date'].min().date()} → {df['date'].max().date()}\")\n",
    "print(\"Label balance:\", round(float(df['y'].mean()), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Leak-safe feature list from artifacts/feature_list.json ---\n",
    "feat_cols = json.loads((ART_DIR/\"feature_list.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "LEAK_WORDS = re.compile(r\"(next|lead|t\\+|ahead|future|target|label)$\", re.I)\n",
    "BAD = {\"y\",\"ret_next\",\"y_next_up\",\"target\",\"label\"}\n",
    "feat_cols = [c for c in feat_cols if c in df.columns and c not in BAD and not LEAK_WORDS.search(c)]\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "assert \"y\" not in feat_cols and \"ret_next\" not in feat_cols, \"Leak columns slipped into features.\"\n",
    "\n",
    "# quick FYI scan (safe: excludes y/ret_next)\n",
    "def _safe_auc(y, x):\n",
    "    try:\n",
    "        return roc_auc_score(y, x) if y.nunique() > 1 else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "top = []\n",
    "if \"ret_next\" in df.columns:\n",
    "    corr_abs = df[feat_cols + [\"ret_next\"]].corr(numeric_only=True)[\"ret_next\"].abs().sort_values(ascending=False)\n",
    "    for c in corr_abs.index[:20]:\n",
    "        if c == \"ret_next\": continue\n",
    "        top.append([c, float(corr_abs[c]), float(_safe_auc(df[\"y\"], df[c]))])\n",
    "else:\n",
    "    for c in feat_cols[:20]:\n",
    "        top.append([c, np.nan, float(_safe_auc(df[\"y\"], df[c]))])\n",
    "\n",
    "leak_scan = pd.DataFrame(top, columns=[\"col\",\"|corr(ret+1)|\",\"AUC(dir ret+1)\"])\n",
    "print(\"Top-20 potential leaks (FYI only):\")\n",
    "print(leak_scan.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build monthly folds with 12-month warmup ---\n",
    "df[\"month\"] = df[\"date\"].dt.to_period(\"M\").astype(str)\n",
    "months = sorted(df[\"month\"].unique())\n",
    "WARMUP_MONTHS = 12\n",
    "test_months = months[WARMUP_MONTHS:]  # start after warm-up\n",
    "print(f\"Folds: {len(test_months)} | first test month: {test_months[0]} | last: {test_months[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e98485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helpers: model, returns, KPIs ---\n",
    "def fit_lr(X, y):\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    Xs = scaler.transform(X)\n",
    "    lr = LogisticRegression(max_iter=200, solver=\"lbfgs\", random_state=RNG)\n",
    "    lr.fit(Xs, y)\n",
    "    return lr, scaler\n",
    "\n",
    "def predict_lr(lr, scaler, X):\n",
    "    return lr.predict_proba(scaler.transform(X))[:, 1]\n",
    "\n",
    "def strat_returns_from_close(prob, close, tau, fee_bps=5.0):\n",
    "    prob = np.asarray(prob)\n",
    "    ret_next = pd.Series(close).pct_change().shift(-1).to_numpy()\n",
    "    pos = (prob >= tau).astype(int)\n",
    "    flips = (np.abs(np.diff(np.r_[0, pos])) > 0).astype(int)\n",
    "    fee = fee_bps / 10000.0\n",
    "    r = pos * ret_next - flips * fee\n",
    "    eq = (1 + pd.Series(r).fillna(0.0)).cumprod()\n",
    "    return r, eq\n",
    "\n",
    "def kpis_from_returns(r, freq=252):\n",
    "    r = pd.Series(r).fillna(0.0)\n",
    "    eq = (1 + r).cumprod()\n",
    "    cagr = (1 + r).prod() ** (freq / max(len(r),1)) - 1\n",
    "    vol  = r.std() * np.sqrt(freq)\n",
    "    sharpe = (cagr / vol) if vol > 0 else np.nan\n",
    "    mdd = (eq / eq.cummax() - 1).min()\n",
    "    hit = (r > 0).mean()\n",
    "    return dict(CAGR=cagr, Sharpe=sharpe, vol_annual=vol,\n",
    "                total_return=(eq.iloc[-1]-1) if len(eq) else 0.0,\n",
    "                max_drawdown=mdd, hit_rate=hit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b38b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Walk-forward training & inference by month ---\n",
    "all_month_rows = []\n",
    "daily_rows = []\n",
    "r_list = []\n",
    "date_list = []\n",
    "\n",
    "# overall buy&hold will be computed after we gather all test dates\n",
    "for m in test_months:\n",
    "    te_idx = df.index[df[\"month\"] == m]\n",
    "    if len(te_idx) == 0: \n",
    "        continue\n",
    "    start_date = df.loc[te_idx[0], \"date\"]\n",
    "    tr_df = df[df[\"date\"] < start_date].copy()\n",
    "    te_df = df.loc[te_idx].copy()\n",
    "\n",
    "    X_tr = tr_df[feat_cols].fillna(0.0).to_numpy()\n",
    "    y_tr = tr_df[\"y\"].astype(int).to_numpy()\n",
    "    X_te = te_df[feat_cols].fillna(0.0).to_numpy()\n",
    "    y_te = te_df[\"y\"].astype(int).to_numpy()\n",
    "\n",
    "    lr, scaler = fit_lr(X_tr, y_tr)\n",
    "    p_te = predict_lr(lr, scaler, X_te)\n",
    "\n",
    "    auc_m = roc_auc_score(y_te, p_te) if y_te.min() != y_te.max() else np.nan\n",
    "    r_m, eq_m = strat_returns_from_close(p_te, te_df[\"close\"].to_numpy(), TAU, fee_bps=FEE_BPS)\n",
    "    k_m = kpis_from_returns(r_m)\n",
    "\n",
    "    all_month_rows.append(dict(month=m, AUC=auc_m, Sharpe=k_m[\"Sharpe\"],\n",
    "                               TotalReturn=k_m[\"total_return\"], N=float(len(te_df))))\n",
    "\n",
    "    pos = (p_te >= TAU).astype(float)\n",
    "    daily_rows.append(pd.DataFrame({\n",
    "        \"date\": te_df[\"date\"].to_numpy(),\n",
    "        \"y\": y_te,\n",
    "        \"prob\": p_te,\n",
    "        \"month\": m,\n",
    "        \"pos\": pos,\n",
    "        \"pos_prev\": np.r_[0, pos[:-1]]\n",
    "    }))\n",
    "\n",
    "    r_list.append(pd.Series(r_m))\n",
    "    date_list.extend(te_df[\"date\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de637d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Consolidate daily stream for plotting/inspection ---\n",
    "daily = pd.concat(daily_rows, ignore_index=True) if daily_rows else pd.DataFrame()\n",
    "r_all = pd.concat(r_list, ignore_index=True) if r_list else pd.Series(dtype=\"float64\")\n",
    "\n",
    "# Buy & Hold on the same dates\n",
    "test_mask = df[\"date\"].isin(daily[\"date\"])\n",
    "close_test = df.loc[test_mask, \"close\"].reset_index(drop=True)\n",
    "ret_mkt = close_test.pct_change().shift(-1)\n",
    "eq_mkt = (1 + ret_mkt.fillna(0.0)).cumprod()\n",
    "eq_strat = (1 + r_all.fillna(0.0)).cumprod()\n",
    "\n",
    "turnover = (np.abs(np.diff(np.r_[0, daily[\"pos\"].to_numpy()])) > 0).mean() if len(daily) else 0.0\n",
    "print(f\"Turnover (avg): {turnover:.4f} | Final equity: {float(eq_strat.iloc[-1]) if len(eq_strat) else 1.0:.6f}\")\n",
    "print(daily[[\"date\",\"y\",\"prob\",\"month\",\"pos\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ad491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot equity curve ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9,4.5))\n",
    "plt.plot(daily.index, eq_mkt.values[:len(daily)], label=\"Buy & Hold\")\n",
    "plt.plot(daily.index, eq_strat.values, label=\"Walk-forward (LR, τ)\")\n",
    "plt.title(\"Equity Curve — Walk-Forward (Monthly Refit)\")\n",
    "plt.xlabel(\"Time (test)\")\n",
    "plt.ylabel(\"Equity (×)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "out_fig = FIG_DIR/\"equity_curve_walkforward.png\"\n",
    "plt.savefig(out_fig, dpi=140)\n",
    "plt.show()\n",
    "print(f\"Saved figure: {out_fig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90774578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NB9 Sanity diagnostics (robust) ---\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# If 'wf' isn't defined, build it from 'daily' + returns from df['close']\n",
    "if \"wf\" not in globals():\n",
    "    if \"daily\" not in globals():\n",
    "        raise RuntimeError(\"Run the walk-forward cells first (the ones that create 'daily').\")\n",
    "    if \"df\" not in globals() or \"close\" not in df.columns or \"date\" not in df.columns:\n",
    "        raise RuntimeError(\"Need 'df' with 'date' and 'close' to compute market returns.\")\n",
    "    tmp = df[[\"date\",\"close\"]].copy()\n",
    "    tmp[\"ret_mkt\"] = tmp[\"close\"].pct_change().shift(-1)\n",
    "    wf = daily.merge(tmp[[\"date\",\"ret_mkt\"]], on=\"date\", how=\"left\")\n",
    "\n",
    "# 1) Return distribution sanity\n",
    "print(\"ret_mkt describe:\\n\", wf[\"ret_mkt\"].describe().to_string(), \"\\n\")\n",
    "big20 = (wf[\"ret_mkt\"].abs() > 0.20).sum()\n",
    "big100 = (wf[\"ret_mkt\"].abs() > 1.00).sum()\n",
    "print(f\"Large |ret_mkt| counts:\\n> 20%: {big20} | > 100%: {big100}\\n\")\n",
    "\n",
    "print(\"Sample of biggest magnitudes:\")\n",
    "cols = [\"date\",\"ret_mkt\"] + [c for c in [\"pos\",\"pos_prev\"] if c in wf.columns]\n",
    "print(wf.loc[wf[\"ret_mkt\"].abs().nlargest(5).index, cols].sort_values(\"date\"))\n",
    "\n",
    "# 2) Label alignment: SAME- vs NEXT-day\n",
    "df_tmp = df[[\"date\",\"y\"]].copy()\n",
    "ret_series = wf.set_index(\"date\")[\"ret_mkt\"]\n",
    "df_tmp[\"ret_mkt\"]  = df_tmp[\"date\"].map(ret_series)\n",
    "df_tmp[\"ret_next\"] = df_tmp[\"ret_mkt\"].shift(-1)\n",
    "\n",
    "same = (df_tmp[\"y\"] == (df_tmp[\"ret_mkt\"]  > 0).astype(int)).mean()\n",
    "nxt  = (df_tmp[\"y\"] == (df_tmp[\"ret_next\"] > 0).astype(int)).mean()\n",
    "base = (df_tmp[\"ret_mkt\"] > 0).mean()\n",
    "\n",
    "print(\"\\nLabel alignment:\")\n",
    "print(\"Match(y, SAME-day up):\", round(float(same), 3))\n",
    "print(\"Match(y, NEXT-day up):\", round(float(nxt), 3))\n",
    "print(\"Baseline up-day rate :\", round(float(base), 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bf7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KPIs + monthly table (preview) ---\n",
    "overall = kpis_from_returns(r_all)\n",
    "overall_s = pd.Series(overall).round(6)\n",
    "print(\"\\nOverall walk-forward:\")\n",
    "print(overall_s)\n",
    "\n",
    "mf = pd.DataFrame(all_month_rows)\n",
    "mf_preview = mf.copy()\n",
    "mf_preview[\"Sharpe\"] = mf_preview[\"Sharpe\"].round(2)\n",
    "mf_preview[\"AUC\"] = mf_preview[\"AUC\"].round(3)\n",
    "mf_preview[\"TotalReturn\"] = (mf_preview[\"TotalReturn\"]*100).map(lambda x: f\"{x:.2f}%\")\n",
    "print(\"\\nHead of per-month metrics:\")\n",
    "print(mf_preview.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b681faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save monthly metrics & summary JSON ---\n",
    "mf.to_csv(DATA_DIR/\"walkforward_metrics.csv\", index=False)\n",
    "\n",
    "summary = {\n",
    "    \"tau\": TAU,\n",
    "    \"fee_bps\": FEE_BPS,\n",
    "    \"slippage_bps\": SLIPPAGE_BPS,\n",
    "    \"overall\": {k: float(v) for k, v in kpis_from_returns(r_all).items()}\n",
    "}\n",
    "(ART_DIR/\"walkforward_summary.json\").write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Saved: {DATA_DIR/'walkforward_metrics.csv'} | {ART_DIR/'walkforward_summary.json'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
