{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f9a41b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' from 'c:\\.projects\\ml-env\\Lib\\site-packages\\torch\\__init__.py' has no attribute 'types' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m sys.path.append(os.path.abspath(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\__init__.py:2150\u001b[39m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2145\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2146\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2148\u001b[39m \n\u001b[32m   2149\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TYPE_CHECKING, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\nn\\__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceLikeType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Buffer, Parameter\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_traceable_wrapper_subclass\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackwardHook, RemovableHandle\n\u001b[32m     21\u001b[39m __all__ = [\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_pre_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mregister_module_forward_hook\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     31\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:298\u001b[39m\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    297\u001b[39m \u001b[38;5;66;03m# Subtypes which have __tensor_flatten__ and __tensor_unflatten__.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTensorWithFlatten\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mProtocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__tensor_flatten__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\.projects\\ml-env\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:339\u001b[39m, in \u001b[36mTensorWithFlatten\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdim\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    334\u001b[39m     ...\n\u001b[32m    336\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    338\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     dtype: \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtypes\u001b[49m._dtype,\n\u001b[32m    340\u001b[39m     non_blocking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    341\u001b[39m     copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    342\u001b[39m     *,\n\u001b[32m    343\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    344\u001b[39m ) -> torch.Tensor:\n\u001b[32m    345\u001b[39m     ...\n\u001b[32m    347\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> torch.Tensor:\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' from 'c:\\.projects\\ml-env\\Lib\\site-packages\\torch\\__init__.py' has no attribute 'types' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import sys, os, importlib, numpy as np, pandas as pd\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import data as data_mod, features as features_mod, utils as utils_mod\n",
    "importlib.reload(data_mod); importlib.reload(features_mod); importlib.reload(utils_mod)\n",
    "from src.data import get_data\n",
    "from src.features import add_features\n",
    "from src.utils import make_labels\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3f4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, pandas, sklearn, matplotlib, yfinance\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"pandas:\", pandas.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)\n",
    "print(\"yfinance:\", yfinance.__version__)\n",
    "\n",
    "# optional checks if you installed them\n",
    "import ta, shap\n",
    "print(\"ta:\", ta.__version__)\n",
    "print(\"shap:\", shap.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dead-zone labels to reduce noise: ±0.1%\n",
    "df = get_data(\"AAPL\", start=\"2015-01-01\", end=\"2023-12-31\")\n",
    "df = add_features(df)\n",
    "df = make_labels(df, tau=0.001, dead_zone=True)\n",
    "\n",
    "drop_cols = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"ret_next\",\"y\"]\n",
    "feat_cols = [c for c in df.columns if c not in drop_cols]\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"y\"].astype(np.float32).values\n",
    "dates = df[\"date\"].values\n",
    "\n",
    "len(df), len(feat_cols), feat_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "i_tr, i_va = int(0.70*n), int(0.85*n)\n",
    "\n",
    "X_tr, y_tr = X[:i_tr], y[:i_tr]\n",
    "X_va, y_va = X[i_tr:i_va], y[i_tr:i_va]\n",
    "X_te, y_te = X[i_va:], y[i_va:]\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr).astype(np.float32)\n",
    "X_va = scaler.transform(X_va).astype(np.float32)\n",
    "X_te = scaler.transform(X_te).astype(np.float32)\n",
    "\n",
    "X_tr.shape, X_va.shape, X_te.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00923228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y, window=30):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.window = window\n",
    "\n",
    "        # build index of valid sequence ends\n",
    "        self.ends = np.arange(window, len(X))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ends)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        end = self.ends[idx]\n",
    "        start = end - self.window\n",
    "        x_seq = self.X[start:end]\n",
    "        y_t = self.y[end]\n",
    "        return torch.from_numpy(x_seq), torch.tensor(y_t, dtype=torch.float32)\n",
    "\n",
    "def make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, window=30, batch=128):\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, window)\n",
    "    ds_va = SeqDataset(X_va, y_va, window)\n",
    "    ds_te = SeqDataset(X_te, y_te, window)\n",
    "\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=False)\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False)\n",
    "    dl_te = DataLoader(ds_te, batch_size=batch, shuffle=False, drop_last=False)\n",
    "    return ds_tr, ds_va, ds_te, dl_tr, dl_va, dl_te\n",
    "\n",
    "window = 30\n",
    "ds_tr, ds_va, ds_te, dl_tr, dl_va, dl_te = make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, window=window, batch=128)\n",
    "len(ds_tr), len(ds_va), len(ds_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f798709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClf(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):         # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]       # last time step\n",
    "        p = self.head(out).squeeze(-1)\n",
    "        return p\n",
    "\n",
    "model = LSTMClf(in_dim=len(feat_cols), hidden=96, layers=1, dropout=0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "bce = nn.BCELoss()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34196199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for xb, yb in dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        p = model(xb)\n",
    "        loss = bce(p, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item() * len(yb)\n",
    "        n += len(yb)\n",
    "    return total / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    Ps, Ys = [], []\n",
    "    for xb, yb in dl:\n",
    "        xb = xb.to(device)\n",
    "        p = model(xb).detach().cpu().numpy()\n",
    "        Ps.append(p)\n",
    "        Ys.append(yb.numpy())\n",
    "    P = np.concatenate(Ps)\n",
    "    Y = np.concatenate(Ys)\n",
    "    pred = (P > 0.5).astype(int)\n",
    "    metrics = {\n",
    "        \"AUC\": float(roc_auc_score(Y, P)) if len(np.unique(Y)) > 1 else float(\"nan\"),\n",
    "        \"BalAcc\": float(balanced_accuracy_score(Y, pred)),\n",
    "        \"F1\": float(f1_score(Y, pred))\n",
    "    }\n",
    "    return metrics, P, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_va_auc = -1\n",
    "best_state = None\n",
    "epochs = 15\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    tr_loss = train_epoch(model, dl_tr)\n",
    "    va_metrics, P_va, Y_va = evaluate(model, dl_va)\n",
    "    if va_metrics[\"AUC\"] > best_va_auc:\n",
    "        best_va_auc = va_metrics[\"AUC\"]\n",
    "        best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "    print(f\"epoch {ep:02d} | loss {tr_loss:.4f} | val AUC {va_metrics['AUC']:.3f} \"\n",
    "          f\"| BalAcc {va_metrics['BalAcc']:.3f} | F1 {va_metrics['F1']:.3f}\")\n",
    "\n",
    "# load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_metrics, P_va, Y_va = evaluate(model, dl_va)\n",
    "te_metrics, P_te, Y_te = evaluate(model, dl_te)\n",
    "\n",
    "print(\"Validation:\", va_metrics)\n",
    "print(\"Test      :\", te_metrics)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix @0.5:\")\n",
    "print(confusion_matrix(Y_te, (P_te>0.5).astype(int)))\n",
    "print(classification_report(Y_te, (P_te>0.5).astype(int), digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1281d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_sharpe_from_probs(p, y_next, fee=0.0010, thr=0.55):\n",
    "    pos = (p > thr).astype(int)\n",
    "    trades = np.abs(np.diff(np.r_[0, pos])) * fee\n",
    "    strat_r = pos * y_next - trades\n",
    "    s = strat_r.std()\n",
    "    return 0.0 if s == 0 else strat_r.mean()/s*np.sqrt(252)\n",
    "\n",
    "# Build aligned VAL/TEST ret_next arrays for the sequence datasets\n",
    "# For a window of W, ds_va[i] predicts y at index i+W; we align returns accordingly:\n",
    "val_slice = slice(int(0.70*len(df)), int(0.85*len(df)))\n",
    "test_slice = slice(int(0.85*len(df)), len(df))\n",
    "\n",
    "val_ret_next = df.iloc[val_slice][\"ret_next\"].values[window:]   # drop first 'window' to align P_va\n",
    "test_ret_next = df.iloc[test_slice][\"ret_next\"].values[window:] # align with P_te\n",
    "\n",
    "grid = np.linspace(0.50, 0.60, 21)\n",
    "scores = [(t, strat_sharpe_from_probs(P_va, val_ret_next, fee=0.0010, thr=t)) for t in grid]\n",
    "thr = max(scores, key=lambda x: x[1])[0]\n",
    "thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fee = 0.0010\n",
    "pos = (P_te > thr).astype(int)\n",
    "trades = np.abs(np.diff(np.r_[0, pos])); costs = trades * fee\n",
    "strat_r = pos * test_ret_next - costs\n",
    "bh_r    = test_ret_next\n",
    "\n",
    "def equity_curve(returns): return (1 + pd.Series(returns)).cumprod()\n",
    "def sharpe(r): s=np.std(r); return 0 if s==0 else np.mean(r)/s*np.sqrt(252)\n",
    "def max_drawdown(eq): peak=eq.cummax(); return (eq/peak - 1).min()\n",
    "\n",
    "eq_s, eq_b = equity_curve(strat_r), equity_curve(bh_r)\n",
    "print(\"LSTM Strategy Sharpe:\", sharpe(strat_r))\n",
    "print(\"Buy&Hold Sharpe    :\", sharpe(bh_r))\n",
    "print(\"LSTM MaxDD:\", max_drawdown(eq_s), \"| BH MaxDD:\", max_drawdown(eq_b))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(eq_s.values, label=f\"LSTM (thr={thr:.2f}, fee=10bps)\")\n",
    "plt.plot(eq_b.values, label=\"Buy & Hold\")\n",
    "plt.title(\"Equity Curve — TEST (LSTM)\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only test-slice predictions aligned with dates (skip first 'window' rows)\n",
    "test_dates = df.iloc[int(0.85*len(df)):][\"date\"].values[window:]\n",
    "out = pd.DataFrame({\n",
    "    \"date\": test_dates,\n",
    "    \"p_lstm\": P_te,          # LSTM test probabilities\n",
    "    \"ret_next\": test_ret_next\n",
    "})\n",
    "out.to_csv(\"../data/aapl_lstm_test_preds.csv\", index=False)\n",
    "\"Saved to data/aapl_lstm_test_preds.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eddd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: coverage & trades on TEST\n",
    "coverage = (P_te > thr).mean()\n",
    "trades = int(np.abs(np.diff(np.r_[0, (P_te > thr).astype(int)])).sum())\n",
    "print(f\"Coverage (days in position): {coverage:.2%}\")\n",
    "print(f\"Trades: {trades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUClf(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=96, layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.Linear(hidden, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):         # x: [B, T, F]\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]       # last time step\n",
    "        return self.head(out).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRUClf(in_dim=len(feat_cols), hidden=96, layers=1, dropout=0.2).to(device)\n",
    "opt = torch.optim.Adam(gru.parameters(), lr=1e-3)\n",
    "bce = nn.BCELoss()\n",
    "\n",
    "best_va_auc_gru, best_state_gru = -1, None\n",
    "epochs = 15\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    tr_loss = train_epoch(gru, dl_tr)\n",
    "    va_metrics, P_va_gru, Y_va_gru = evaluate(gru, dl_va)\n",
    "    if va_metrics[\"AUC\"] > best_va_auc_gru:\n",
    "        best_va_auc_gru = va_metrics[\"AUC\"]\n",
    "        best_state_gru = {k: v.cpu().clone() for k, v in gru.state_dict().items()}\n",
    "    print(f\"[GRU] epoch {ep:02d} | loss {tr_loss:.4f} | val AUC {va_metrics['AUC']:.3f} \"\n",
    "          f\"| BalAcc {va_metrics['BalAcc']:.3f} | F1 {va_metrics['F1']:.3f}\")\n",
    "\n",
    "if best_state_gru is not None:\n",
    "    gru.load_state_dict(best_state_gru)\n",
    "\n",
    "# final metrics\n",
    "va_metrics_gru, P_va_gru, Y_va_gru = evaluate(gru, dl_va)\n",
    "te_metrics_gru, P_te_gru, Y_te_gru = evaluate(gru, dl_te)\n",
    "print(\"Validation (GRU):\", va_metrics_gru)\n",
    "print(\"Test (GRU):\", te_metrics_gru)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a434382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses your existing funcs: strat_sharpe_from_probs, equity_curve/sharpe/max_drawdown (defined earlier)\n",
    "\n",
    "# Align returns (same as LSTM): drop first `window` to match sequence outputs\n",
    "val_slice  = slice(int(0.70*len(df)), int(0.85*len(df)))\n",
    "test_slice = slice(int(0.85*len(df)), len(df))\n",
    "val_ret_next  = df.iloc[val_slice][\"ret_next\"].values[window:]\n",
    "test_ret_next = df.iloc[test_slice][\"ret_next\"].values[window:]\n",
    "\n",
    "grid = np.linspace(0.50, 0.60, 21)\n",
    "thr_gru = max(grid, key=lambda t: strat_sharpe_from_probs(P_va_gru, val_ret_next, fee=0.0010, thr=t))\n",
    "thr_gru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a819969",
   "metadata": {},
   "outputs": [],
   "source": [
    "fee = 0.0010\n",
    "pos = (P_te_gru > thr_gru).astype(int)\n",
    "trades = np.abs(np.diff(np.r_[0, pos])); costs = trades * fee\n",
    "strat_r = pos * test_ret_next - costs\n",
    "bh_r    = test_ret_next\n",
    "\n",
    "def equity_curve(returns): return (1 + pd.Series(returns)).cumprod()\n",
    "def sharpe(r): s=np.std(r); return 0 if s==0 else np.mean(r)/s*np.sqrt(252)\n",
    "def max_drawdown(eq): peak=eq.cummax(); return (eq/peak - 1).min()\n",
    "\n",
    "eq_s, eq_b = equity_curve(strat_r), equity_curve(bh_r)\n",
    "print(\"GRU Strategy Sharpe:\", sharpe(strat_r))\n",
    "print(\"Buy&Hold Sharpe    :\", sharpe(bh_r))\n",
    "print(\"GRU MaxDD:\", max_drawdown(eq_s), \"| BH MaxDD:\", max_drawdown(eq_b))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(eq_s.values, label=f\"GRU (thr={thr_gru:.2f}, fee=10bps)\")\n",
    "plt.plot(eq_b.values, label=\"Buy & Hold\")\n",
    "plt.title(\"Equity Curve — TEST (GRU)\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = (P_te_gru > thr_gru).mean()\n",
    "trades = int(np.abs(np.diff(np.r_[0,(P_te_gru>thr_gru).astype(int)])).sum())\n",
    "print(f\"Coverage (days in position): {coverage:.2%}\")\n",
    "print(f\"Trades: {trades}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(P_te_gru, bins=30)\n",
    "plt.axvline(0.5, ls=\"--\"); plt.axvline(thr_gru, color=\"r\")\n",
    "plt.title(\"GRU predicted probabilities (TEST)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    (\"LSTM\", 64, 1, 0.2),\n",
    "    (\"LSTM\", 128, 1, 0.2),\n",
    "    (\"GRU\",  64, 1, 0.2),\n",
    "    (\"GRU\",  128, 1, 0.2),\n",
    "]\n",
    "def run_config(kind, hidden, layers, dropout):\n",
    "    if kind==\"LSTM\":\n",
    "        m = LSTMClf(in_dim=len(feat_cols), hidden=hidden, layers=layers, dropout=dropout).to(device)\n",
    "    else:\n",
    "        m = GRUClf(in_dim=len(feat_cols), hidden=hidden, layers=layers, dropout=dropout).to(device)\n",
    "    opt = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "    best = -1\n",
    "    for _ in range(8):\n",
    "        _ = train_epoch(m, dl_tr)\n",
    "        metrics, _, _ = evaluate(m, dl_va)\n",
    "        best = max(best, metrics[\"AUC\"])\n",
    "    return best\n",
    "\n",
    "rows = []\n",
    "for kind, hidden, layers, dropout in configs:\n",
    "    auc = run_config(kind, hidden, layers, dropout)\n",
    "    rows.append({\"model\": kind, \"hidden\": hidden, \"layers\": layers, \"dropout\": dropout, \"val_auc_best\": round(auc,4)})\n",
    "pd.DataFrame(rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
