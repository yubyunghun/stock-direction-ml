{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2f9a41b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions:\n",
      " - python: 3.13.7\n",
      " - numpy: 2.3.3\n",
      " - pandas: 2.3.2\n",
      " - sklearn: 1.7.2\n",
      " - matplotlib: 3.10.6\n",
      " - torch: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Imports & versions (PyTorch edition) ---\n",
    "import os, json, math, pathlib, hashlib, random, warnings, re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, brier_score_loss, log_loss,\n",
    "    accuracy_score, precision_score, recall_score, roc_curve\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# persistence\n",
    "import joblib\n",
    "\n",
    "# PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    TORCH_OK = True\n",
    "except Exception as e:\n",
    "    TORCH_OK = False\n",
    "    print(\"PyTorch not available in this env. Install torch and restart the kernel.\\n\", e)\n",
    "\n",
    "print(\"Versions:\")\n",
    "print(\" - python:\",  \"{}.{}.{}\".format(*__import__('sys').version_info[:3]))\n",
    "print(\" - numpy:\", np.__version__)\n",
    "print(\" - pandas:\", pd.__version__)\n",
    "print(\" - sklearn:\", __import__('sklearn').__version__)\n",
    "print(\" - matplotlib:\", plt.matplotlib.__version__)\n",
    "if TORCH_OK:\n",
    "    print(\" - torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4fafc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED=42, LOOKBACK=60, HORIZON=1, STRIDE=1, BATCH_SIZE=256, EPOCHS=100, LR=0.001, device=cpu\n"
     ]
    }
   ],
   "source": [
    "# --- Config, folders, seeds, device ---\n",
    "SEED = 42\n",
    "LOOKBACK = 60     # timesteps per window\n",
    "HORIZON  = 1      # predict t+1 direction\n",
    "STRIDE   = 1\n",
    "\n",
    "TRAIN_FRAC = 0.70\n",
    "VAL_FRAC   = 0.15   # TEST_FRAC = 0.15\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS     = 100\n",
    "LR         = 1e-3\n",
    "PATIENCE   = 10      # early stopping patience\n",
    "EPS_IMPROVE = 1e-5   # minimum AUC improvement to count\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "ART_DIR  = Path(\"artifacts\")\n",
    "FIG_DIR  = Path(\"reports/figures\")\n",
    "for p in [DATA_DIR, ART_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if TORCH_OK:\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    try:\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if TORCH_OK and torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"SEED={SEED}, LOOKBACK={LOOKBACK}, HORIZON={HORIZON}, STRIDE={STRIDE}, \"\n",
    "      f\"BATCH_SIZE={BATCH_SIZE}, EPOCHS={EPOCHS}, LR={LR}, device={device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d21c4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_nb02 from parquet: shape=(2686, 22), date_range=[2015-02-06 → 2025-10-10]\n",
      "NA total: 0\n",
      "Duplicate dates: 0\n",
      "First 5 features: ['close', 'high', 'low', 'macd', 'macd_signal'] (total: 15)\n"
     ]
    }
   ],
   "source": [
    "# --- Load Phase-2 dataset & feature list (auto-bootstrap if missing) ---\n",
    "df_path_parquet = DATA_DIR / \"df_nb02.parquet\"\n",
    "df_path_csv     = DATA_DIR / \"df_nb02.csv\"\n",
    "features_path   = DATA_DIR / \"feature_list.json\"\n",
    "\n",
    "# 1) Load dataset\n",
    "if df_path_parquet.exists():\n",
    "    df = pd.read_parquet(df_path_parquet); source = \"parquet\"\n",
    "elif df_path_csv.exists():\n",
    "    df = pd.read_csv(df_path_csv); source = \"csv\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"Missing data/df_nb02.parquet or data/df_nb02.csv (run Phase-2 first).\")\n",
    "\n",
    "# 2) Date column\n",
    "dt_col = next((c for c in [\"date\",\"Date\",\"timestamp\",\"Timestamp\",\"ts\",\"datetime\",\"Datetime\"] if c in df.columns), None)\n",
    "if dt_col is None:\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            pd.to_datetime(df[c].head(50), errors=\"raise\"); dt_col = c; break\n",
    "        except Exception:\n",
    "            pass\n",
    "if dt_col is None:\n",
    "    raise KeyError(\"No datetime column found; please rename your time column to 'date'.\")\n",
    "\n",
    "df[dt_col] = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
    "if df[dt_col].isna().all():\n",
    "    raise ValueError(f\"Could not parse datetime column '{dt_col}'.\")\n",
    "df = df.sort_values(dt_col).reset_index(drop=True)\n",
    "\n",
    "# 3) Label must exist\n",
    "if \"y\" not in df.columns:\n",
    "    raise KeyError(\"Label column 'y' not found in dataset.\")\n",
    "\n",
    "# 4) Features: load or create (numeric & non-leaky)\n",
    "if features_path.exists():\n",
    "    with open(features_path, \"r\") as f:\n",
    "        features = json.load(f)\n",
    "    features = [c for c in features if c in df.columns]\n",
    "else:\n",
    "    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    leak_re = re.compile(r\"(next|t\\+?1|lead|future|target|label)\", re.IGNORECASE)\n",
    "    features = [c for c in num_cols if c not in {dt_col, \"y\"} and not leak_re.search(c)]\n",
    "    features.sort()\n",
    "    with open(features_path, \"w\") as f:\n",
    "        json.dump(features, f, indent=2)\n",
    "    print(f\"[created] {features_path} with {len(features)} features\")\n",
    "\n",
    "if not features:\n",
    "    raise RuntimeError(\"Feature list is empty after reconciliation.\")\n",
    "\n",
    "# 5) Report\n",
    "print(f\"Loaded df_nb02 from {source}: shape={df.shape}, \"\n",
    "      f\"date_range=[{df[dt_col].min().date()} → {df[dt_col].max().date()}]\")\n",
    "print(\"NA total:\", int(df.isna().sum().sum()))\n",
    "print(\"Duplicate dates:\", int(df.duplicated(dt_col).sum()))\n",
    "print(\"First 5 features:\", features[:5], f\"(total: {len(features)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5f3f4bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split rows (pre-window): train 1880 val 403 test 403\n",
      "Date ranges:\n",
      "  train: 2015-02-06 → 2022-07-26\n",
      "  val  : 2022-07-27 → 2024-03-04\n",
      "  test : 2024-03-05 → 2025-10-10\n",
      "Saved: artifacts\\nb3_split_info.json\n"
     ]
    }
   ],
   "source": [
    "# --- Chronological splits ---\n",
    "N = len(df)\n",
    "train_end = int(N * TRAIN_FRAC)\n",
    "val_end   = int(N * (TRAIN_FRAC + VAL_FRAC))\n",
    "\n",
    "df_train = df.iloc[:train_end].copy()\n",
    "df_val   = df.iloc[train_end:val_end].copy()\n",
    "df_test  = df.iloc[val_end:].copy()\n",
    "\n",
    "print(\"Split rows (pre-window):\",\n",
    "      \"train\", len(df_train), \"val\", len(df_val), \"test\", len(df_test))\n",
    "print(\"Date ranges:\")\n",
    "print(\"  train:\", df_train[dt_col].min().date(), \"→\", df_train[dt_col].max().date())\n",
    "print(\"  val  :\", df_val[dt_col].min().date(),   \"→\", df_val[dt_col].max().date())\n",
    "print(\"  test :\", df_test[dt_col].min().date(),  \"→\", df_test[dt_col].max().date())\n",
    "\n",
    "assert df_train[dt_col].max() < df_val[dt_col].min(), \"Train/Val dates overlap\"\n",
    "assert df_val[dt_col].max()   < df_test[dt_col].min(), \"Val/Test dates overlap\"\n",
    "\n",
    "split_info = {\n",
    "    \"SEED\": SEED,\n",
    "    \"LOOKBACK\": LOOKBACK, \"HORIZON\": HORIZON, \"STRIDE\": STRIDE,\n",
    "    \"TRAIN_FRAC\": TRAIN_FRAC, \"VAL_FRAC\": VAL_FRAC,\n",
    "    \"train_end_idx\": train_end, \"val_end_idx\": val_end,\n",
    "    \"train_date_range\": [str(df_train[dt_col].min().date()), str(df_train[dt_col].max().date())],\n",
    "    \"val_date_range\":   [str(df_val[dt_col].min().date()),   str(df_val[dt_col].max().date())],\n",
    "    \"test_date_range\":  [str(df_test[dt_col].min().date()),  str(df_test[dt_col].max().date())],\n",
    "}\n",
    "with open(ART_DIR / \"nb3_split_info.json\", \"w\") as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "print(\"Saved:\", ART_DIR / \"nb3_split_info.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "96e9a84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved → artifacts\\lstm_scaler.joblib\n",
      "scaler.mean_ (first 5): [66.44055386 67.14243458 65.67384116  0.43824461  0.43467065]\n"
     ]
    }
   ],
   "source": [
    "# --- Scaling (train only) ---\n",
    "X_train_raw = df_train[features].values.astype(np.float32)\n",
    "X_val_raw   = df_val[features].values.astype(np.float32)\n",
    "X_test_raw  = df_test[features].values.astype(np.float32)\n",
    "\n",
    "y_train_all = df_train[\"y\"].astype(int).values\n",
    "y_val_all   = df_val[\"y\"].astype(int).values\n",
    "y_test_all  = df_test[\"y\"].astype(int).values\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_raw)  # fit ONLY on train\n",
    "X_train_s = scaler.transform(X_train_raw)\n",
    "X_val_s   = scaler.transform(X_val_raw)\n",
    "X_test_s  = scaler.transform(X_test_raw)\n",
    "\n",
    "joblib.dump(scaler, ART_DIR / \"lstm_scaler.joblib\")\n",
    "print(\"Scaler saved →\", ART_DIR / \"lstm_scaler.joblib\")\n",
    "print(\"scaler.mean_ (first 5):\", scaler.mean_[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1fd1ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows created (L=60, H=1, stride=1)\n",
      "  train: (1820, 60, 15) (1820,)\n",
      "  val  : (343, 60, 15) (343,)\n",
      "  test : (343, 60, 15) (343,)\n",
      "Alignment samples (train):\n",
      "  window_end=2015-05-04 → target=2015-05-05 (OK)\n",
      "  window_end=2018-12-11 → target=2018-12-12 (OK)\n",
      "  window_end=2022-07-25 → target=2022-07-26 (OK)\n",
      "Alignment samples (val):\n",
      "  window_end=2022-10-19 → target=2022-10-20 (OK)\n",
      "  window_end=2023-06-27 → target=2023-06-28 (OK)\n",
      "  window_end=2024-03-01 → target=2024-03-04 (OK)\n",
      "Alignment samples (test):\n",
      "  window_end=2024-05-29 → target=2024-05-30 (OK)\n",
      "  window_end=2025-02-04 → target=2025-02-05 (OK)\n",
      "  window_end=2025-10-09 → target=2025-10-10 (OK)\n",
      "Target date overlaps (should be 0): train∩val= 0  val∩test= 0  train∩test= 0\n",
      "Saved target dates to artifacts/.\n"
     ]
    }
   ],
   "source": [
    "# --- Windowing ---\n",
    "def make_windows(X, y, dates, L, H, stride=1):\n",
    "    \"\"\"\n",
    "    Sliding windows of length L predicting label at t+H.\n",
    "    Returns Xw (N,L,F), yw (N,), window end dates, and target dates.\n",
    "    \"\"\"\n",
    "    Xw, yw, end_dates, target_dates = [], [], [], []\n",
    "    N = len(X)\n",
    "    for start in range(0, N - L - (H - 1), stride):\n",
    "        end = start + L\n",
    "        tgt = end + (H - 1)\n",
    "        if tgt >= N:\n",
    "            break\n",
    "        Xw.append(X[start:end])\n",
    "        yw.append(y[tgt])\n",
    "        end_dates.append(dates[end - 1])\n",
    "        target_dates.append(dates[tgt])\n",
    "    return np.array(Xw, np.float32), np.array(yw, np.int32), np.array(end_dates), np.array(target_dates)\n",
    "\n",
    "d_tr, d_va, d_te = df_train[dt_col].values, df_val[dt_col].values, df_test[dt_col].values\n",
    "X_tr_w, y_tr_w, end_tr, tgt_tr = make_windows(X_train_s, y_train_all, d_tr, LOOKBACK, HORIZON, STRIDE)\n",
    "X_va_w, y_va_w, end_va, tgt_va = make_windows(X_val_s,   y_val_all,   d_va, LOOKBACK, HORIZON, STRIDE)\n",
    "X_te_w, y_te_w, end_te, tgt_te = make_windows(X_test_s,  y_test_all,  d_te, LOOKBACK, HORIZON, STRIDE)\n",
    "\n",
    "print(f\"Windows created (L={LOOKBACK}, H={HORIZON}, stride={STRIDE})\")\n",
    "print(\"  train:\", X_tr_w.shape, y_tr_w.shape)\n",
    "print(\"  val  :\", X_va_w.shape, y_va_w.shape)\n",
    "print(\"  test :\", X_te_w.shape, y_te_w.shape)\n",
    "\n",
    "def show_alignment(end_dates, target_dates, k=3, label=\"train\"):\n",
    "    k = min(k, len(end_dates))\n",
    "    print(f\"Alignment samples ({label}):\")\n",
    "    for i in np.linspace(0, len(end_dates)-1, k, dtype=int):\n",
    "        print(f\"  window_end={pd.to_datetime(str(end_dates[i])).date()} → \"\n",
    "              f\"target={pd.to_datetime(str(target_dates[i])).date()} (OK)\")\n",
    "\n",
    "show_alignment(end_tr, tgt_tr, 3, \"train\")\n",
    "show_alignment(end_va, tgt_va, 3, \"val\")\n",
    "show_alignment(end_te, tgt_te, 3, \"test\")\n",
    "\n",
    "print(\"Target date overlaps (should be 0): \"\n",
    "      \"train∩val=\", np.isin(tgt_tr, tgt_va).sum(),\n",
    "      \" val∩test=\", np.isin(tgt_va, tgt_te).sum(),\n",
    "      \" train∩test=\", np.isin(tgt_tr, tgt_te).sum())\n",
    "\n",
    "np.save(ART_DIR / \"train_target_dates.npy\", tgt_tr)\n",
    "np.save(ART_DIR / \"val_target_dates.npy\",   tgt_va)\n",
    "np.save(ART_DIR / \"test_target_dates.npy\",  tgt_te)\n",
    "print(\"Saved target dates to artifacts/.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "00923228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready: L=60, F=15, train batches=8\n"
     ]
    }
   ],
   "source": [
    "# --- PyTorch Dataset & DataLoaders ---\n",
    "if not TORCH_OK:\n",
    "    raise RuntimeError(\"PyTorch not available; install torch and restart the kernel.\")\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "ds_tr = SeqDataset(X_tr_w, y_tr_w)\n",
    "ds_va = SeqDataset(X_va_w, y_va_w)\n",
    "ds_te = SeqDataset(X_te_w, y_te_w)\n",
    "\n",
    "dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True,  drop_last=False)\n",
    "dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "dl_te = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "F = X_tr_w.shape[-1]\n",
    "L = X_tr_w.shape[1]\n",
    "print(f\"DataLoaders ready: L={L}, F={F}, train batches={len(dl_tr)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7f798709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (lstm1): LSTM(15, 64, batch_first=True)\n",
      "  (lstm2): LSTM(64, 32, batch_first=True)\n",
      "  (do1): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Total parameters: 33313\n"
     ]
    }
   ],
   "source": [
    "# --- Model (PyTorch) ---\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden1=64, hidden2=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden1, hidden2, batch_first=True)\n",
    "        self.do1 = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden2, 1)  # logits\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, F)\n",
    "        out, _ = self.lstm1(x)\n",
    "        out, _ = self.lstm2(out)\n",
    "        out = out[:, -1, :]         # last timestep\n",
    "        out = self.do1(out)\n",
    "        logit = self.fc(out).squeeze(-1)  # (B,)\n",
    "        return logit\n",
    "\n",
    "model = LSTMClassifier(input_dim=F, hidden1=64, hidden2=32, dropout=0.2).to(device)\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(model)\n",
    "print(\"Total parameters:\", n_params)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "34196199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | train AUC 0.4833 | val AUC 0.5537\n",
      "Epoch   2 | train AUC 0.4984 | val AUC 0.5527\n",
      "Epoch   3 | train AUC 0.5149 | val AUC 0.5578\n",
      "Epoch   4 | train AUC 0.5074 | val AUC 0.5530\n",
      "Epoch   5 | train AUC 0.5130 | val AUC 0.5436\n",
      "Epoch   6 | train AUC 0.5183 | val AUC 0.5429\n",
      "Epoch   7 | train AUC 0.5448 | val AUC 0.5410\n",
      "Epoch   8 | train AUC 0.5244 | val AUC 0.5363\n",
      "Epoch   9 | train AUC 0.5451 | val AUC 0.5355\n",
      "Epoch  10 | train AUC 0.5420 | val AUC 0.5361\n",
      "Epoch  11 | train AUC 0.5442 | val AUC 0.5383\n",
      "Epoch  12 | train AUC 0.5556 | val AUC 0.5438\n",
      "Epoch  13 | train AUC 0.5514 | val AUC 0.5454\n",
      "Early stopping at epoch 13 (best val AUC 0.5578 @ epoch 3)\n",
      "Best epoch: 3  best val_AUC: 0.5578\n",
      "Saved training curve: reports\\figures\\lstm_nb3_training_curve.png\n",
      "Saved best model → artifacts\\lstm_nb3.pt\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop with EarlyStopping on val AUC ---\n",
    "def sigmoid_np(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "best_val_auc = -np.inf\n",
    "best_epoch = None\n",
    "epochs_no_improve = 0\n",
    "train_auc_hist, val_auc_hist = [], []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_logits = []\n",
    "    train_targets = []\n",
    "    train_loss_accum = 0.0\n",
    "\n",
    "    for Xb, yb in dl_tr:\n",
    "        Xb = Xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_accum += loss.item() * Xb.size(0)\n",
    "        train_logits.append(logits.detach().cpu().numpy())\n",
    "        train_targets.append(yb.detach().cpu().numpy())\n",
    "\n",
    "    train_logits = np.concatenate(train_logits) if train_logits else np.array([])\n",
    "    train_targets = np.concatenate(train_targets) if train_targets else np.array([])\n",
    "    if train_logits.size > 0:\n",
    "        train_probs = sigmoid_np(train_logits)\n",
    "        train_auc = roc_auc_score(train_targets, train_probs)\n",
    "    else:\n",
    "        train_auc = np.nan\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_logits = []\n",
    "    val_targets = []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in dl_va:\n",
    "            Xb = Xb.to(device); yb = yb.to(device)\n",
    "            logits = model(Xb)\n",
    "            val_logits.append(logits.detach().cpu().numpy())\n",
    "            val_targets.append(yb.detach().cpu().numpy())\n",
    "    val_logits = np.concatenate(val_logits)\n",
    "    val_targets = np.concatenate(val_targets)\n",
    "    val_probs = sigmoid_np(val_logits)\n",
    "    val_auc = roc_auc_score(val_targets, val_probs)\n",
    "\n",
    "    train_auc_hist.append(train_auc)\n",
    "    val_auc_hist.append(val_auc)\n",
    "\n",
    "    print(f\"Epoch {epoch:3d} | train AUC {train_auc:.4f} | val AUC {val_auc:.4f}\")\n",
    "\n",
    "    # Early stopping on val AUC\n",
    "    if val_auc > best_val_auc + EPS_IMPROVE:\n",
    "        best_val_auc = val_auc\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), ART_DIR / \"lstm_nb3.pt\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch} (best val AUC {best_val_auc:.4f} @ epoch {best_epoch})\")\n",
    "            break\n",
    "\n",
    "print(f\"Best epoch: {best_epoch}  best val_AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Training curve figure\n",
    "plt.figure()\n",
    "plt.plot(train_auc_hist, label=\"train AUC\")\n",
    "plt.plot(val_auc_hist, label=\"val AUC\")\n",
    "plt.xlabel(\"epoch\"); plt.ylabel(\"AUC\"); plt.legend(); plt.title(\"LSTM NB3 (PyTorch) — AUC vs epoch\")\n",
    "fig_path = FIG_DIR / \"lstm_nb3_training_curve.png\"\n",
    "plt.savefig(fig_path, bbox_inches=\"tight\", dpi=150); plt.close()\n",
    "print(\"Saved training curve:\", fig_path)\n",
    "print(\"Saved best model →\", ART_DIR / \"lstm_nb3.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f18d4c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         model  AUC_test  Brier_test  LogLoss_test  Acc@0.5  Prec@0.5  Rec@0.5\n",
      "0  lstm_nb3_pt    0.5439      0.2503        0.6937   0.4577    0.5455   0.1875\n",
      "Saved figures: reports\\figures\\lstm_nb3_roc.png and reports\\figures\\lstm_nb3_calib.png\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation on test ---\n",
    "# Reload best model\n",
    "reload_model = LSTMClassifier(input_dim=F, hidden1=64, hidden2=32, dropout=0.2).to(device)\n",
    "reload_model.load_state_dict(torch.load(ART_DIR / \"lstm_nb3.pt\", map_location=device))\n",
    "reload_model.eval()\n",
    "\n",
    "# Get test logits\n",
    "test_logits = []\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in dl_te:\n",
    "        Xb = Xb.to(device)\n",
    "        logits = reload_model(Xb)\n",
    "        test_logits.append(logits.detach().cpu().numpy())\n",
    "test_logits = np.concatenate(test_logits)\n",
    "p_test = 1.0 / (1.0 + np.exp(-test_logits))   # sigmoid\n",
    "y_true = y_te_w.astype(int)\n",
    "\n",
    "# Metrics\n",
    "auc   = roc_auc_score(y_true, p_test)\n",
    "brier = brier_score_loss(y_true, p_test)\n",
    "ll    = log_loss(y_true, p_test, labels=[0,1])\n",
    "acc   = accuracy_score(y_true, (p_test >= 0.5).astype(int))\n",
    "prec  = precision_score(y_true, (p_test >= 0.5).astype(int), zero_division=0)\n",
    "rec   = recall_score(y_true, (p_test >= 0.5).astype(int), zero_division=0)\n",
    "\n",
    "metrics_df = pd.DataFrame([{\n",
    "    \"model\": \"lstm_nb3_pt\",\n",
    "    \"AUC_test\": round(auc, 4),\n",
    "    \"Brier_test\": round(brier, 4),\n",
    "    \"LogLoss_test\": round(ll, 4),\n",
    "    \"Acc@0.5\": round(acc, 4),\n",
    "    \"Prec@0.5\": round(prec, 4),\n",
    "    \"Rec@0.5\": round(rec, 4),\n",
    "}])\n",
    "print(metrics_df)\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, p_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC={auc:.3f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"LSTM NB3 (PyTorch) — ROC (test)\"); plt.legend()\n",
    "roc_path = FIG_DIR / \"lstm_nb3_roc.png\"\n",
    "plt.savefig(roc_path, bbox_inches=\"tight\", dpi=150); plt.close()\n",
    "\n",
    "# Calibration plot\n",
    "prob_true, prob_pred = calibration_curve(y_true, p_test, n_bins=10, strategy=\"uniform\")\n",
    "plt.figure()\n",
    "plt.plot(prob_pred, prob_true, marker=\"o\", label=\"Calibrated\")\n",
    "plt.plot([0,1],[0,1],'--', label=\"Perfect\")\n",
    "plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Observed frequency\"); plt.title(\"LSTM NB3 (PyTorch) — Calibration\")\n",
    "plt.legend()\n",
    "calib_path = FIG_DIR / \"lstm_nb3_calib.png\"\n",
    "plt.savefig(calib_path, bbox_inches=\"tight\", dpi=150); plt.close()\n",
    "\n",
    "print(\"Saved figures:\", roc_path, \"and\", calib_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c02c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved config: artifacts\\nb3_lstm_config.json\n",
      "Updated metrics summary: data\\explainability_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Save run config & metrics summary ---\n",
    "feat_hash = hashlib.md5(\"\\n\".join(map(str, sorted(features))).encode()).hexdigest()\n",
    "config = {\n",
    "    \"framework\": \"pytorch\",\n",
    "    \"seed\": SEED,\n",
    "    \"lookback\": LOOKBACK,\n",
    "    \"horizon\": HORIZON,\n",
    "    \"stride\": STRIDE,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"learning_rate\": LR,\n",
    "    \"train_frac\": TRAIN_FRAC,\n",
    "    \"val_frac\": VAL_FRAC,\n",
    "    \"feature_hash\": feat_hash,\n",
    "    \"n_features\": len(features),\n",
    "    \"best_val_auc\": float(best_val_auc) if not np.isnan(best_val_auc) else None,\n",
    "    \"generated_at\": datetime.now().isoformat(timespec=\"seconds\")\n",
    "}\n",
    "cfg_path = ART_DIR / \"nb3_lstm_config.json\"\n",
    "with open(cfg_path, \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(\"Saved config:\", cfg_path)\n",
    "\n",
    "summary_path = DATA_DIR / \"explainability_summary.csv\"\n",
    "try:\n",
    "    old = pd.read_csv(summary_path)\n",
    "except Exception:\n",
    "    old = pd.DataFrame(columns=list(metrics_df.columns))\n",
    "new = pd.concat([old, metrics_df], ignore_index=True)\n",
    "new.to_csv(summary_path, index=False)\n",
    "print(\"Updated metrics summary:\", summary_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fa1281d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max|p_test - p_test_reload| = 0.0\n",
      "Reload parity OK\n"
     ]
    }
   ],
   "source": [
    "# --- Reload parity test ---\n",
    "# Compute predictions again with a freshly reloaded model\n",
    "reloaded2 = LSTMClassifier(input_dim=F, hidden1=64, hidden2=32, dropout=0.2).to(device)\n",
    "reloaded2.load_state_dict(torch.load(ART_DIR / \"lstm_nb3.pt\", map_location=device))\n",
    "reloaded2.eval()\n",
    "\n",
    "test_logits_reload = []\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in dl_te:\n",
    "        Xb = Xb.to(device)\n",
    "        logits = reloaded2(Xb)\n",
    "        test_logits_reload.append(logits.detach().cpu().numpy())\n",
    "test_logits_reload = np.concatenate(test_logits_reload)\n",
    "p_test_reload = 1.0 / (1.0 + np.exp(-test_logits_reload))\n",
    "\n",
    "max_abs_diff = float(np.max(np.abs(p_test - p_test_reload)))\n",
    "print(\"max|p_test - p_test_reload| =\", max_abs_diff)\n",
    "print(\"Reload parity OK\" if max_abs_diff <= 1e-7 else \"Reload parity WARNING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b12c92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts\\lstm_nb3.pt → exists: True\n",
      "artifacts\\lstm_scaler.joblib → exists: True\n",
      "artifacts\\nb3_lstm_config.json → exists: True\n",
      "artifacts\\nb3_split_info.json → exists: True\n",
      "artifacts\\train_target_dates.npy → exists: True\n",
      "artifacts\\val_target_dates.npy → exists: True\n",
      "artifacts\\test_target_dates.npy → exists: True\n",
      "data\\explainability_summary.csv → exists: True\n",
      "reports\\figures\\lstm_nb3_roc.png → exists: True\n",
      "reports\\figures\\lstm_nb3_calib.png → exists: True\n",
      "reports\\figures\\lstm_nb3_training_curve.png → exists: True\n"
     ]
    }
   ],
   "source": [
    "# --- Artifact checklist ---\n",
    "paths = [\n",
    "    ART_DIR / \"lstm_nb3.pt\",               # PyTorch weights\n",
    "    ART_DIR / \"lstm_scaler.joblib\",\n",
    "    ART_DIR / \"nb3_lstm_config.json\",\n",
    "    ART_DIR / \"nb3_split_info.json\",\n",
    "    ART_DIR / \"train_target_dates.npy\",\n",
    "    ART_DIR / \"val_target_dates.npy\",\n",
    "    ART_DIR / \"test_target_dates.npy\",\n",
    "    DATA_DIR / \"explainability_summary.csv\",\n",
    "    FIG_DIR / \"lstm_nb3_roc.png\",\n",
    "    FIG_DIR / \"lstm_nb3_calib.png\",\n",
    "    FIG_DIR / \"lstm_nb3_training_curve.png\",\n",
    "]\n",
    "for p in paths:\n",
    "    print(f\"{p} → exists: {p.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b02bcf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligned shapes → p_tst: (342,) ret_tgt: (342,)\n",
      "Candidate long thresholds (from val quantiles): [0.507, 0.508, 0.509, 0.509, 0.51, 0.511, 0.511, 0.513, 0.516]\n",
      "\n",
      "Validation band (top 5):\n",
      " thr_long  take_rate  prec_pos  rec_pos   f1_pos\n",
      " 0.513480   0.151603  0.692308      1.0 0.818182\n",
      " 0.515743   0.102041  0.657143      1.0 0.793103\n",
      " 0.511335   0.201166  0.608696      1.0 0.756757\n",
      " 0.510702   0.250729  0.569767      1.0 0.725926\n",
      " 0.509197   0.349854  0.558333      1.0 0.716578\n",
      "Chosen long-only threshold: 0.5134802281856536\n",
      "\n",
      "Backtest summary (test):\n",
      " thr_long  days  take_rate  avg_daily_ret_%  ann_sharpe  total_ret_%\n",
      "  0.51348   342   0.026316         0.013162    0.591059     4.501466\n"
     ]
    }
   ],
   "source": [
    "# --- Align returns to TEST target dates and run a practical long/flat band ---\n",
    "\n",
    "# 1) Build next-day returns and align to test TARGET dates\n",
    "df_bt = df[[dt_col, \"close\"]].copy()\n",
    "df_bt[\"ret1\"] = df_bt[\"close\"].pct_change().shift(-1)\n",
    "df_bt = df_bt.set_index(dt_col)\n",
    "\n",
    "# target dates already computed during windowing as `tgt_te`\n",
    "target_dates_test = pd.to_datetime(pd.Index(tgt_te))\n",
    "ret_tgt = df_bt.loc[target_dates_test, \"ret1\"].values  # same length as p_tst\n",
    "\n",
    "# Drop any NaNs that may arise at the tail\n",
    "mask = ~np.isnan(ret_tgt)\n",
    "ret_tgt = ret_tgt[mask]\n",
    "p_tst_aligned = p_tst[mask]\n",
    "print(\"Aligned shapes → p_tst:\", p_tst_aligned.shape, \"ret_tgt:\", ret_tgt.shape)\n",
    "\n",
    "# 2) Choose a practical long-only threshold grid using validation percentiles\n",
    "#    (ensures we actually take some trades)\n",
    "q_grid = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90]\n",
    "thr_candidates = np.unique(np.quantile(p_val, q_grid))  # from validation probs\n",
    "print(\"Candidate long thresholds (from val quantiles):\", np.round(thr_candidates, 3).tolist())\n",
    "\n",
    "def band_metrics(y_true, p, thr_long):\n",
    "    take = (p >= thr_long).astype(int)\n",
    "    take_rate = float(take.mean())\n",
    "    if take.sum() == 0:\n",
    "        return {\"thr_long\": float(thr_long), \"take_rate\": 0.0, \"prec_pos\": np.nan, \"rec_pos\": np.nan, \"f1_pos\": np.nan}\n",
    "    y_sel = y_true[take==1]\n",
    "    p_sel = p[take==1]\n",
    "    yhat_sel = (p_sel >= 0.5).astype(int)  # hit-rate among taken trades\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_sel, yhat_sel, average=\"binary\", zero_division=0)\n",
    "    return {\"thr_long\": float(thr_long), \"take_rate\": take_rate, \"prec_pos\": float(prec), \"rec_pos\": float(rec), \"f1_pos\": float(f1)}\n",
    "\n",
    "# Tune on validation\n",
    "val_band = pd.DataFrame([band_metrics(yv, p_val, t) for t in thr_candidates])\\\n",
    "             .sort_values([\"f1_pos\",\"prec_pos\",\"take_rate\"], ascending=[False, False, True])\n",
    "print(\"\\nValidation band (top 5):\")\n",
    "print(val_band.head(5).to_string(index=False))\n",
    "\n",
    "best_t_long = float(val_band.iloc[0][\"thr_long\"])\n",
    "print(\"Chosen long-only threshold:\", best_t_long)\n",
    "\n",
    "# 3) Backtest on test (aligned) with simple transaction costs\n",
    "TC_BPS = 5  # 0.05% per position change\n",
    "pos = (p_tst_aligned >= best_t_long).astype(int)\n",
    "\n",
    "# Costs when position changes (enter/exit)\n",
    "pos_shift = np.r_[0, pos[:-1]]\n",
    "turnover = (pos != pos_shift).astype(int)\n",
    "\n",
    "net_ret = pos * ret_tgt - turnover * (TC_BPS / 10000.0)\n",
    "\n",
    "def sharpe(x):\n",
    "    x = np.asarray(x)\n",
    "    mu, sd = np.nanmean(x), np.nanstd(x)\n",
    "    return 0.0 if sd == 0 else (mu / sd) * np.sqrt(252)\n",
    "\n",
    "bt = {\n",
    "    \"thr_long\": best_t_long,\n",
    "    \"days\": int(len(net_ret)),\n",
    "    \"take_rate\": float(pos.mean()),\n",
    "    \"avg_daily_ret_%\": float(np.nanmean(net_ret) * 100),\n",
    "    \"ann_sharpe\": float(sharpe(net_ret)),\n",
    "    \"total_ret_%\": float(np.nansum(net_ret) * 100),\n",
    "}\n",
    "print(\"\\nBacktest summary (test):\")\n",
    "print(pd.DataFrame([bt]).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
