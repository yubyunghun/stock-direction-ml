{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, importlib, numpy as np, pandas as pd\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import data as data_mod, features as features_mod, utils as utils_mod\n",
    "importlib.reload(data_mod); importlib.reload(features_mod); importlib.reload(utils_mod)\n",
    "from src.data import get_data\n",
    "from src.features import add_features\n",
    "from src.utils import make_labels\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(\"AAPL\", start=\"2015-01-01\", end=\"2023-12-31\")\n",
    "df = add_features(df)\n",
    "df = make_labels(df, tau=0.0)\n",
    "\n",
    "# Feature columns = everything except these\n",
    "drop_cols = [\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"ret_next\",\"y\"]\n",
    "feat_cols = [c for c in df.columns if c not in drop_cols]\n",
    "X = df[feat_cols].values.astype(np.float32)\n",
    "y = df[\"y\"].astype(np.float32).values\n",
    "dates = df[\"date\"].values\n",
    "\n",
    "len(df), len(feat_cols), feat_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "i_tr, i_va = int(0.70*n), int(0.85*n)\n",
    "\n",
    "X_tr, y_tr = X[:i_tr], y[:i_tr]\n",
    "X_va, y_va = X[i_tr:i_va], y[i_tr:i_va]\n",
    "X_te, y_te = X[i_va:], y[i_va:]\n",
    "\n",
    "scaler = StandardScaler().fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr).astype(np.float32)\n",
    "X_va = scaler.transform(X_va).astype(np.float32)\n",
    "X_te = scaler.transform(X_te).astype(np.float32)\n",
    "\n",
    "X_tr.shape, X_va.shape, X_te.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00923228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y, window=30):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.window = window\n",
    "\n",
    "        # build index of valid sequence ends\n",
    "        self.ends = np.arange(window, len(X))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ends)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        end = self.ends[idx]\n",
    "        start = end - self.window\n",
    "        x_seq = self.X[start:end]\n",
    "        y_t = self.y[end]\n",
    "        return torch.from_numpy(x_seq), torch.tensor(y_t, dtype=torch.float32)\n",
    "\n",
    "def make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, window=30, batch=128):\n",
    "    ds_tr = SeqDataset(X_tr, y_tr, window)\n",
    "    ds_va = SeqDataset(X_va, y_va, window)\n",
    "    ds_te = SeqDataset(X_te, y_te, window)\n",
    "\n",
    "    dl_tr = DataLoader(ds_tr, batch_size=batch, shuffle=True, drop_last=False)\n",
    "    dl_va = DataLoader(ds_va, batch_size=batch, shuffle=False, drop_last=False)\n",
    "    dl_te = DataLoader(ds_te, batch_size=batch, shuffle=False, drop_last=False)\n",
    "    return ds_tr, ds_va, ds_te, dl_tr, dl_va, dl_te\n",
    "\n",
    "window = 30\n",
    "ds_tr, ds_va, ds_te, dl_tr, dl_va, dl_te = make_loaders(X_tr, y_tr, X_va, y_va, X_te, y_te, window=window, batch=128)\n",
    "len(ds_tr), len(ds_va), len(ds_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f798709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClf(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, layers=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_dim,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if layers > 1 else 0.0\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):         # x: [B, T, F]\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]       # last time step\n",
    "        p = self.head(out).squeeze(-1)\n",
    "        return p\n",
    "\n",
    "model = LSTMClf(in_dim=len(feat_cols), hidden=96, layers=1, dropout=0.2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "bce = nn.BCELoss()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34196199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "    for xb, yb in dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        p = model(xb)\n",
    "        loss = bce(p, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item() * len(yb)\n",
    "        n += len(yb)\n",
    "    return total / max(n,1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    Ps, Ys = [], []\n",
    "    for xb, yb in dl:\n",
    "        xb = xb.to(device)\n",
    "        p = model(xb).detach().cpu().numpy()\n",
    "        Ps.append(p)\n",
    "        Ys.append(yb.numpy())\n",
    "    P = np.concatenate(Ps)\n",
    "    Y = np.concatenate(Ys)\n",
    "    pred = (P > 0.5).astype(int)\n",
    "    metrics = {\n",
    "        \"AUC\": float(roc_auc_score(Y, P)) if len(np.unique(Y)) > 1 else float(\"nan\"),\n",
    "        \"BalAcc\": float(balanced_accuracy_score(Y, pred)),\n",
    "        \"F1\": float(f1_score(Y, pred))\n",
    "    }\n",
    "    return metrics, P, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_va_auc = -1\n",
    "best_state = None\n",
    "epochs = 15\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    tr_loss = train_epoch(model, dl_tr)\n",
    "    va_metrics, P_va, Y_va = evaluate(model, dl_va)\n",
    "    if va_metrics[\"AUC\"] > best_va_auc:\n",
    "        best_va_auc = va_metrics[\"AUC\"]\n",
    "        best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n",
    "    print(f\"epoch {ep:02d} | loss {tr_loss:.4f} | val AUC {va_metrics['AUC']:.3f} \"\n",
    "          f\"| BalAcc {va_metrics['BalAcc']:.3f} | F1 {va_metrics['F1']:.3f}\")\n",
    "\n",
    "# load best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "va_metrics, P_va, Y_va = evaluate(model, dl_va)\n",
    "te_metrics, P_te, Y_te = evaluate(model, dl_te)\n",
    "\n",
    "print(\"Validation:\", va_metrics)\n",
    "print(\"Test      :\", te_metrics)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix @0.5:\")\n",
    "print(confusion_matrix(Y_te, (P_te>0.5).astype(int)))\n",
    "print(classification_report(Y_te, (P_te>0.5).astype(int), digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1281d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat_sharpe_from_probs(p, y_next, fee=0.0010, thr=0.55):\n",
    "    pos = (p > thr).astype(int)\n",
    "    trades = np.abs(np.diff(np.r_[0, pos])) * fee\n",
    "    strat_r = pos * y_next - trades\n",
    "    s = strat_r.std()\n",
    "    return 0.0 if s == 0 else strat_r.mean()/s*np.sqrt(252)\n",
    "\n",
    "# Build aligned VAL/TEST ret_next arrays for the sequence datasets\n",
    "# For a window of W, ds_va[i] predicts y at index i+W; we align returns accordingly:\n",
    "val_slice = slice(int(0.70*len(df)), int(0.85*len(df)))\n",
    "test_slice = slice(int(0.85*len(df)), len(df))\n",
    "\n",
    "val_ret_next = df.iloc[val_slice][\"ret_next\"].values[window:]   # drop first 'window' to align P_va\n",
    "test_ret_next = df.iloc[test_slice][\"ret_next\"].values[window:] # align with P_te\n",
    "\n",
    "grid = np.linspace(0.50, 0.60, 21)\n",
    "scores = [(t, strat_sharpe_from_probs(P_va, val_ret_next, fee=0.0010, thr=t)) for t in grid]\n",
    "thr = max(scores, key=lambda x: x[1])[0]\n",
    "thr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fee = 0.0010\n",
    "pos = (P_te > thr).astype(int)\n",
    "trades = np.abs(np.diff(np.r_[0, pos])); costs = trades * fee\n",
    "strat_r = pos * test_ret_next - costs\n",
    "bh_r    = test_ret_next\n",
    "\n",
    "def equity_curve(returns): return (1 + pd.Series(returns)).cumprod()\n",
    "def sharpe(r): s=np.std(r); return 0 if s==0 else np.mean(r)/s*np.sqrt(252)\n",
    "def max_drawdown(eq): peak=eq.cummax(); return (eq/peak - 1).min()\n",
    "\n",
    "eq_s, eq_b = equity_curve(strat_r), equity_curve(bh_r)\n",
    "print(\"LSTM Strategy Sharpe:\", sharpe(strat_r))\n",
    "print(\"Buy&Hold Sharpe    :\", sharpe(bh_r))\n",
    "print(\"LSTM MaxDD:\", max_drawdown(eq_s), \"| BH MaxDD:\", max_drawdown(eq_b))\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(eq_s.values, label=f\"LSTM (thr={thr:.2f}, fee=10bps)\")\n",
    "plt.plot(eq_b.values, label=\"Buy & Hold\")\n",
    "plt.title(\"Equity Curve â€” TEST (LSTM)\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de52ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only test-slice predictions aligned with dates (skip first 'window' rows)\n",
    "test_dates = df.iloc[int(0.85*len(df)):][\"date\"].values[window:]\n",
    "out = pd.DataFrame({\n",
    "    \"date\": test_dates,\n",
    "    \"p_lstm\": P_te,\n",
    "    \"ret_next\": test_ret_next\n",
    "})\n",
    "out.to_csv(\"../data/aapl_lstm_test_preds.csv\", index=False)\n",
    "\"Saved to data/aapl_lstm_test_preds.csv\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
