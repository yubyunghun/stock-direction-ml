{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & params ---\n",
    "import json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "ART_DIR  = Path(\"artifacts\")\n",
    "FIG_DIR  = Path(\"reports/figures\")\n",
    "for p in [DATA_DIR, ART_DIR, FIG_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Backtest knobs\n",
    "FEE_BPS      = 5.0      # round-trip trading cost in bps (e.g., 5 = 0.05%)\n",
    "SLIPPAGE_BPS = 0.0      # extra bps per trade (optional)\n",
    "TAU_GRID     = np.linspace(0.50, 0.65, 16)  # probability threshold sweep\n",
    "ALLOW_SHORT  = False     # True → 3-way long/short/flat; False → long/flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split loader with Parquet-or-CSV fallback (drop-in replacement for Cell 2) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _can_parquet():\n",
    "    try:\n",
    "        import pyarrow  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            import fastparquet  # noqa: F401\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "def write_table(df: pd.DataFrame, base: Path):\n",
    "    \"\"\"\n",
    "    Save to <base>.parquet if a parquet engine is installed, else <base>.csv\n",
    "    Returns the actual Path written.\n",
    "    \"\"\"\n",
    "    if _can_parquet():\n",
    "        path = base.with_suffix(\".parquet\")\n",
    "        df.to_parquet(path, index=False)\n",
    "    else:\n",
    "        path = base.with_suffix(\".csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "    return path\n",
    "\n",
    "def read_table(base: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read from <base>.parquet if it exists, else <base>.csv.\n",
    "    \"\"\"\n",
    "    p_parq = base.with_suffix(\".parquet\")\n",
    "    p_csv  = base.with_suffix(\".csv\")\n",
    "    if p_parq.exists():\n",
    "        return pd.read_parquet(p_parq)\n",
    "    if p_csv.exists():\n",
    "        return pd.read_csv(p_csv)\n",
    "    raise FileNotFoundError(f\"Neither {p_parq.name} nor {p_csv.name} exists.\")\n",
    "\n",
    "# --- Load train/test splits; rebuild from df_nb02.csv if missing ---\n",
    "def rebuild_splits_from_phase2():\n",
    "    base_csv = DATA_DIR / \"df_nb02.csv\"\n",
    "    if not base_csv.exists():\n",
    "        raise FileNotFoundError(\"Missing data/df_nb02.csv (Phase 2).\")\n",
    "    df = pd.read_csv(base_csv)\n",
    "\n",
    "    # time order if available\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "        df = df.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    label_col = next((c for c in [\"y\",\"target\",\"label\",\"y_next_up\"] if c in df.columns), None)\n",
    "    if label_col is None:\n",
    "        raise RuntimeError(\"No label column in df_nb02.csv (expected y/target/label/y_next_up).\")\n",
    "\n",
    "    y = df.pop(label_col).astype(int)\n",
    "    # drop obvious non-features\n",
    "    X = df.drop(columns=[c for c in [\"date\",\"ticker\",\"symbol\",\"spy_close\",\"vix_close\"] if c in df.columns], errors=\"ignore\")\n",
    "    X = X.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "    n = len(X); cut = int(n*0.8)\n",
    "    X_tr, X_te = X.iloc[:cut].copy(), X.iloc[cut:].copy()\n",
    "    y_tr, y_te = y.iloc[:cut].copy(), y.iloc[cut:].copy()\n",
    "\n",
    "    # persist for next runs (Parquet if possible, else CSV)\n",
    "    write_table(X_tr, DATA_DIR / \"train\")\n",
    "    write_table(X_te, DATA_DIR / \"test\")\n",
    "    write_table(pd.DataFrame({\"y\": y_tr}), DATA_DIR / \"y_train\")\n",
    "    write_table(pd.DataFrame({\"y\": y_te}), DATA_DIR / \"y_test\")\n",
    "    print(\"Rebuilt splits → data/train.*, data/test.*, y_*.{parquet|csv}\")\n",
    "    return X_tr, X_te, y_tr.values, y_te.values\n",
    "\n",
    "train_base = DATA_DIR / \"train\"\n",
    "test_base  = DATA_DIR / \"test\"\n",
    "ytr_base   = DATA_DIR / \"y_train\"\n",
    "yte_base   = DATA_DIR / \"y_test\"\n",
    "\n",
    "try:\n",
    "    X_tr = read_table(train_base).copy()\n",
    "    X_te = read_table(test_base).copy()\n",
    "except FileNotFoundError:\n",
    "    X_tr, X_te, y_tr, y_te = rebuild_splits_from_phase2()\n",
    "else:\n",
    "    # labels either embedded or separate y files\n",
    "    label_col = next((c for c in [\"y\",\"target\",\"label\",\"y_next_up\"] if c in X_tr.columns), None)\n",
    "    if label_col:\n",
    "        y_tr = X_tr.pop(label_col).astype(int).values\n",
    "        y_te = X_te.pop(label_col).astype(int).values\n",
    "    else:\n",
    "        y_tr = read_table(ytr_base).iloc[:,0].astype(int).values\n",
    "        y_te = read_table(yte_base).iloc[:,0].astype(int).values\n",
    "\n",
    "print(\"Loaded splits:\", X_tr.shape, X_te.shape, \"| labels:\", len(y_tr), len(y_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45440579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load models ---\n",
    "import joblib\n",
    "path_lr  = ART_DIR / \"lr.joblib\"      # your saved LR model\n",
    "path_xgb = ART_DIR / \"model_xgb.pkl\"  # only if you trained/saved XGB\n",
    "\n",
    "HAS_LR  = path_lr.exists()\n",
    "HAS_XGB = path_xgb.exists()\n",
    "\n",
    "mdl_lr  = joblib.load(path_lr)  if HAS_LR  else None\n",
    "mdl_xgb = joblib.load(path_xgb) if HAS_XGB else None\n",
    "print(\"HAS_LR:\", HAS_LR, \"| HAS_XGB:\", HAS_XGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdf1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Align features to training spec + apply scaler, then predict ---\n",
    "import json\n",
    "\n",
    "# 1) feature list\n",
    "feat_path   = ART_DIR / \"feature_list.json\"\n",
    "scaler_path = ART_DIR / \"scaler.joblib\"\n",
    "\n",
    "if feat_path.exists():\n",
    "    with open(feat_path, \"r\") as fh:\n",
    "        feat_list = json.load(fh)\n",
    "elif HAS_LR and hasattr(mdl_lr, \"feature_names_in_\"):\n",
    "    feat_list = list(mdl_lr.feature_names_in_)\n",
    "else:\n",
    "    raise RuntimeError(\"Missing artifacts/feature_list.json and model has no feature_names_in_.\")\n",
    "\n",
    "def conform(df, cols):\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "    return df[cols].copy()\n",
    "\n",
    "X_tr_aligned = conform(X_tr, feat_list)\n",
    "X_te_aligned = conform(X_te, feat_list)\n",
    "\n",
    "# 2) scaler\n",
    "if scaler_path.exists():\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    X_tr_in = scaler.transform(X_tr_aligned.values)\n",
    "    X_te_in = scaler.transform(X_te_aligned.values)\n",
    "else:\n",
    "    X_tr_in = X_tr_aligned.values\n",
    "    X_te_in = X_te_aligned.values\n",
    "\n",
    "print(\"Aligned shapes:\", X_tr_in.shape, X_te_in.shape)\n",
    "print(\"Model expects:\", getattr(mdl_lr, 'n_features_in_', 'unknown'))\n",
    "\n",
    "# 3) predict (use aligned arrays!)\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "probs = {}\n",
    "\n",
    "if HAS_LR and mdl_lr is not None:\n",
    "    probs[\"LR\"] = mdl_lr.predict_proba(X_te_in)[:, 1]\n",
    "\n",
    "if HAS_XGB and mdl_xgb is not None:\n",
    "    # XGB usually trained on same feat_list; scale only if you trained it with scaling\n",
    "    probs[\"XGB\"] = mdl_xgb.predict_proba(X_te_aligned.values)[:, 1]\n",
    "\n",
    "# quick metrics\n",
    "rows = []\n",
    "for name, p in probs.items():\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"AUC_test\": float(roc_auc_score(y_te, p)),\n",
    "        \"Brier_test\": float(brier_score_loss(y_te, p)),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"n\": int(len(p)),\n",
    "    })\n",
    "pd.DataFrame(rows).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict on test (aligned) ---\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "probs = {}\n",
    "\n",
    "# LR uses the scaled/aligned matrix\n",
    "if HAS_LR and mdl_lr is not None:\n",
    "    probs[\"LR\"] = mdl_lr.predict_proba(X_te_in)[:, 1]\n",
    "\n",
    "# XGB (if present) uses aligned *unscaled* features unless you also scaled at train time\n",
    "if HAS_XGB and mdl_xgb is not None:\n",
    "    probs[\"XGB\"] = mdl_xgb.predict_proba(X_te_aligned.values)[:, 1]\n",
    "\n",
    "if not probs:\n",
    "    raise RuntimeError(\"No models available to predict. Ensure lr.joblib or model_xgb.pkl exists.\")\n",
    "\n",
    "# Quick metrics table\n",
    "rows = []\n",
    "for name, p in probs.items():\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"AUC_test\": float(roc_auc_score(y_te, p)),\n",
    "        \"Brier_test\": float(brier_score_loss(y_te, p)),\n",
    "        \"mean_p\": float(np.mean(p)),\n",
    "        \"n\": int(len(p)),\n",
    "    })\n",
    "metrics = pd.DataFrame(rows).round(4)\n",
    "display(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90474c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Build next-day returns (ret1) aligned to test period length ---\n",
    "base_csv = DATA_DIR / \"df_nb02.csv\"\n",
    "df_all = pd.read_csv(base_csv)\n",
    "if \"date\" not in df_all.columns:\n",
    "    raise KeyError(\"'date' missing in df_nb02.csv\")\n",
    "df_all[\"date\"] = pd.to_datetime(df_all[\"date\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "df_all = df_all.dropna(subset=[\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "price_col = next((c for c in [\"adj_close\",\"Adj Close\",\"close\",\"Close\",\"price\"] if c in df_all.columns), None)\n",
    "if price_col is None:\n",
    "    raise RuntimeError(\"No price column found in df_nb02.csv (need adj_close/close).\")\n",
    "\n",
    "df_all[\"ret1\"] = pd.Series(df_all[price_col]).pct_change().shift(-1)\n",
    "\n",
    "N = len(y_te)\n",
    "df_test_slice = df_all.iloc[-N:].copy().reset_index(drop=True)\n",
    "dates_te = df_test_slice[\"date\"].values\n",
    "r_next   = df_test_slice[\"ret1\"].fillna(0.0).values\n",
    "\n",
    "print(\"Test span:\", df_test_slice['date'].min(), \"→\", df_test_slice['date'].max(), \"| n=\", len(df_test_slice))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464adc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backtest helpers ---\n",
    "def positions_from_probs(p, tau, allow_short=False):\n",
    "    if allow_short:\n",
    "        return np.where(p>tau, 1.0, np.where(p<1.0-tau, -1.0, 0.0))\n",
    "    return (p > tau).astype(float)\n",
    "\n",
    "def trade_costs_from_positions(pos, fee_bps=5.0, slippage_bps=0.0):\n",
    "    return (abs(np.diff(np.r_[0.0, pos])) * (fee_bps + slippage_bps)) / 1e4\n",
    "\n",
    "def equity_curve(returns, pos, fee_bps=5.0, slippage_bps=0.0):\n",
    "    gross = pos * returns\n",
    "    costs = trade_costs_from_positions(pos, fee_bps, slippage_bps)\n",
    "    net   = gross - costs\n",
    "    eq = (1.0 + net).cumprod()\n",
    "    return eq, {\"gross\": gross, \"costs\": costs, \"net\": net}\n",
    "\n",
    "def perf_metrics(net_ret, dates=None, periods_per_year=252):\n",
    "    tot_ret = float(np.prod(1.0 + net_ret) - 1.0)\n",
    "    if dates is not None and len(dates)>1:\n",
    "        years = (pd.to_datetime(dates[-1]) - pd.to_datetime(dates[0])).days / 365.25\n",
    "        cagr = (1.0 + tot_ret)**(1.0/years) - 1.0 if years>0 else np.nan\n",
    "    else:\n",
    "        years = len(net_ret)/periods_per_year\n",
    "        cagr = (1.0 + tot_ret)**(1.0/years) - 1.0 if years>0 else np.nan\n",
    "\n",
    "    mu = np.mean(net_ret); sd = np.std(net_ret, ddof=1)\n",
    "    sharpe = (mu/(sd + 1e-12)) * np.sqrt(periods_per_year)\n",
    "\n",
    "    curve = np.cumprod(1.0 + net_ret)\n",
    "    peak  = np.maximum.accumulate(curve)\n",
    "    maxdd = float((curve/peak - 1.0).min())\n",
    "\n",
    "    hit_rate = float(np.mean(net_ret > 0.0))\n",
    "    turnover = float(np.mean(np.abs(np.diff(np.r_[0.0, (net_ret!=0).astype(float)]))))\n",
    "\n",
    "    return {\"total_return\": float(tot_ret), \"CAGR\": float(cagr), \"vol_annual\": float(sd*np.sqrt(periods_per_year)),\n",
    "            \"Sharpe\": float(sharpe), \"max_drawdown\": maxdd, \"hit_rate\": hit_rate, \"turnover\": turnover}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15203eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sweep tau and pick best Sharpe per model ---\n",
    "results = []\n",
    "curves  = {}\n",
    "\n",
    "for name, p in probs.items():\n",
    "    best = None\n",
    "    for tau in TAU_GRID:\n",
    "        pos = positions_from_probs(p, tau, allow_short=ALLOW_SHORT)\n",
    "        eq, parts = equity_curve(r_next, pos, FEE_BPS, SLIPPAGE_BPS)\n",
    "        metrics = perf_metrics(parts[\"net\"], dates_te)\n",
    "        row = {\"model\": name, \"tau\": float(tau), **metrics}\n",
    "        results.append(row)\n",
    "        if best is None or metrics[\"Sharpe\"] > best[\"Sharpe\"]:\n",
    "            best = {**row}\n",
    "            curves[name] = (eq, pos, parts)\n",
    "    print(f\"{name}: best Sharpe @ tau={best['tau']:.3f} | Sharpe={best['Sharpe']:.2f} | CAGR={best['CAGR']:.2%}\")\n",
    "\n",
    "bt_df = pd.DataFrame(results).sort_values([\"model\",\"Sharpe\"], ascending=[True, False])\n",
    "display(bt_df.head(12))\n",
    "\n",
    "out_csv = DATA_DIR / \"multiticker_tau_sweep.csv\"\n",
    "bt_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80538428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Equity curve plots (best per model) ---\n",
    "for name, (eq, pos, parts) in curves.items():\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(eq, label=f\"{name}\")\n",
    "    plt.title(f\"Equity Curve – {name}\")\n",
    "    plt.xlabel(\"Time (test)\")\n",
    "    plt.ylabel(\"Equity (x)\")\n",
    "    plt.grid(True, alpha=.3)\n",
    "    plt.legend()\n",
    "    out = FIG_DIR / f\"equity_curve_{name.lower()}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e09544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Backtest summary JSON ---\n",
    "summary = {\"fee_bps\": FEE_BPS, \"slippage_bps\": SLIPPAGE_BPS, \"allow_short\": ALLOW_SHORT, \"models\": {}}\n",
    "\n",
    "for name in probs.keys():\n",
    "    best_row = bt_df[bt_df[\"model\"]==name].iloc[0].to_dict()\n",
    "    summary[\"models\"][name] = {\n",
    "        \"tau\": best_row[\"tau\"],\n",
    "        \"Sharpe\": best_row[\"Sharpe\"],\n",
    "        \"CAGR\": best_row[\"CAGR\"],\n",
    "        \"max_drawdown\": best_row[\"max_drawdown\"],\n",
    "        \"hit_rate\": best_row[\"hit_rate\"],\n",
    "        \"total_return\": best_row[\"total_return\"],\n",
    "        \"vol_annual\": best_row[\"vol_annual\"]\n",
    "    }\n",
    "\n",
    "out_json = ART_DIR / \"backtest_summary.json\"\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Wrote:\", out_json)\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: overlay buy & hold with best-τ strategy ---\n",
    "# best τ for LR from the sweep table\n",
    "best_tau_lr = float(\n",
    "    bt_df[bt_df[\"model\"]==\"LR\"].sort_values(\"Sharpe\", ascending=False).iloc[0][\"tau\"]\n",
    ")\n",
    "\n",
    "# Buy & hold = always in the market, no fees\n",
    "bh_eq, _ = equity_curve(r_next, np.ones_like(r_next), fee_bps=0.0, slippage_bps=0.0)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(bh_eq, label=\"Buy & Hold\")\n",
    "\n",
    "# Plot each strategy curve you saved in `curves`\n",
    "for name, (eq, _, _) in curves.items():\n",
    "    plt.plot(eq, label=f\"{name} (best τ)\")\n",
    "\n",
    "plt.title(\"Equity Curve — Strategy vs Buy & Hold\")\n",
    "plt.xlabel(\"Time (test)\"); plt.ylabel(\"Equity (x)\")\n",
    "plt.grid(True, alpha=.3); plt.legend(); plt.tight_layout()\n",
    "out = FIG_DIR / \"equity_curve_vs_buyhold.png\"\n",
    "plt.savefig(out, dpi=150); plt.close()\n",
    "print(\"Saved:\", out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optional: fee sensitivity for LR at best τ ---\n",
    "fees_bps = [0, 2.5, 5, 10, 20]\n",
    "best_tau_lr = float(\n",
    "    bt_df[bt_df[\"model\"]==\"LR\"].sort_values(\"Sharpe\", ascending=False).iloc[0][\"tau\"]\n",
    ")\n",
    "pos_lr = (probs[\"LR\"] > best_tau_lr).astype(float)\n",
    "\n",
    "rows = []\n",
    "for fbps in fees_bps:\n",
    "    eq, parts = equity_curve(r_next, pos_lr, fee_bps=fbps, slippage_bps=0.0)\n",
    "    m = perf_metrics(parts[\"net\"], dates_te)\n",
    "    rows.append({\"fee_bps\": fbps, **m})\n",
    "\n",
    "sens = pd.DataFrame(rows).round(4)\n",
    "display(sens)\n",
    "sens.to_csv(DATA_DIR / \"multiticker_fee_sweep_AAPL_LR.csv\", index=False)\n",
    "print(\"Saved:\", DATA_DIR / \"multiticker_fee_sweep_AAPL_LR.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c500ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best LR threshold: 0.54\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "best_tau = float(pd.read_csv(\"data/multiticker_tau_sweep.csv\")\n",
    "                 .sort_values([\"model\",\"Sharpe\"], ascending=[True, False])\n",
    "                 .query(\"model=='LR'\").iloc[0][\"tau\"])\n",
    "with open(\"artifacts/threshold.json\",\"w\") as f:\n",
    "    json.dump({\"LR\":{\"tau\":best_tau}}, f, indent=2)\n",
    "print(\"Saved best LR threshold:\", best_tau)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (.venv stock-direction-ml)",
   "language": "python",
   "name": "stock-direction-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
